{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cleander/analise-de-sentimentos/blob/main/analise_de_sentimentos_bertimbal_pi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIwE2ItxDpiE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "080da4c2-d0c8-4b0b-bd8c-0f65b67d7bf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "pip install transformers datasets torch pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8mwsLQlDp30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "c6ecc360-eb0a-4018-b335-7db5a382c1fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   original_index                                        review_text  \\\n",
              "0           97262             Perfeito....chegou antes do prazo.....   \n",
              "1           72931  Foi uma ótima compra! Chegou antes mesmo do pr...   \n",
              "2           19659     Recebi muito rapido e um otimo custo beneficio   \n",
              "3           43054                                          Recomendo   \n",
              "4           59202  Só veio uma capa comprei 3 aí paguei. Mais de ...   \n",
              "\n",
              "                               review_text_processed  \\\n",
              "0             perfeito....chegou antes do prazo.....   \n",
              "1  foi uma otima compra! chegou antes mesmo do pr...   \n",
              "2     recebi muito rapido e um otimo custo beneficio   \n",
              "3                                          recomendo   \n",
              "4  so veio uma capa comprei 3 ai paguei. mais de ...   \n",
              "\n",
              "                               review_text_tokenized  polarity  rating  \\\n",
              "0     ['perfeito', 'chegou', 'antes', 'do', 'prazo']       1.0       5   \n",
              "1  ['foi', 'uma', 'otima', 'compra', 'chegou', 'a...       1.0       5   \n",
              "2  ['recebi', 'muito', 'rapido', 'um', 'otimo', '...       1.0       5   \n",
              "3                                      ['recomendo']       1.0       5   \n",
              "4  ['so', 'veio', 'uma', 'capa', 'comprei', 'ai',...       0.0       1   \n",
              "\n",
              "   kfold_polarity  kfold_rating  \n",
              "0               1             1  \n",
              "1               1             1  \n",
              "2               1             1  \n",
              "3               1             1  \n",
              "4               1             1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fcc57fe6-50f9-4dea-a4ca-35d324c7c541\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_index</th>\n",
              "      <th>review_text</th>\n",
              "      <th>review_text_processed</th>\n",
              "      <th>review_text_tokenized</th>\n",
              "      <th>polarity</th>\n",
              "      <th>rating</th>\n",
              "      <th>kfold_polarity</th>\n",
              "      <th>kfold_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>97262</td>\n",
              "      <td>Perfeito....chegou antes do prazo.....</td>\n",
              "      <td>perfeito....chegou antes do prazo.....</td>\n",
              "      <td>['perfeito', 'chegou', 'antes', 'do', 'prazo']</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>72931</td>\n",
              "      <td>Foi uma ótima compra! Chegou antes mesmo do pr...</td>\n",
              "      <td>foi uma otima compra! chegou antes mesmo do pr...</td>\n",
              "      <td>['foi', 'uma', 'otima', 'compra', 'chegou', 'a...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19659</td>\n",
              "      <td>Recebi muito rapido e um otimo custo beneficio</td>\n",
              "      <td>recebi muito rapido e um otimo custo beneficio</td>\n",
              "      <td>['recebi', 'muito', 'rapido', 'um', 'otimo', '...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43054</td>\n",
              "      <td>Recomendo</td>\n",
              "      <td>recomendo</td>\n",
              "      <td>['recomendo']</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>59202</td>\n",
              "      <td>Só veio uma capa comprei 3 aí paguei. Mais de ...</td>\n",
              "      <td>so veio uma capa comprei 3 ai paguei. mais de ...</td>\n",
              "      <td>['so', 'veio', 'uma', 'capa', 'comprei', 'ai',...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcc57fe6-50f9-4dea-a4ca-35d324c7c541')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fcc57fe6-50f9-4dea-a4ca-35d324c7c541 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fcc57fe6-50f9-4dea-a4ca-35d324c7c541');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-50f183b9-cdb0-402c-a534-43b06237a7fe\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-50f183b9-cdb0-402c-a534-43b06237a7fe')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-50f183b9-cdb0-402c-a534-43b06237a7fe button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 41744,\n  \"fields\": [\n    {\n      \"column\": \"original_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28894,\n        \"min\": 3,\n        \"max\": 99999,\n        \"num_unique_values\": 41744,\n        \"samples\": [\n          57902,\n          44445,\n          40301\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 36920,\n        \"samples\": [\n          \"Compra e entrega sem problemas\",\n          \"\\u00d3timo produto entrega r\\u00e1pida \",\n          \"Comprei um atuador de freio para minha maquina...paguei a vista...fiquei quase 20 dias esperando paguei o frete...e quando recebo o produto uma decep\\u00e7\\u00e3o...mandaram produto errado...enviaram uma placa \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_text_processed\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 36190,\n        \"samples\": [\n          \"chegou rapido, lacrado e bem embalado\",\n          \"produto com qualidade. recomendo a compra, esse e o segundo produto que compro.\",\n          \"chegou antes do esperado e o produto e lindo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_text_tokenized\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33929,\n        \"samples\": [\n          \"['faltou', 'colocar', 'no', 'pedido', 'nome', 'completo', 'deixei', 'endereco', 'de', 'onde', 'trabalho', 'para', 'entrega', 'tem', 'pessoas', 'com', 'mesmo', 'nome']\",\n          \"['produto', 'recebido', 'no', 'prazo']\",\n          \"['entrega', 'bemmm', 'antes', 'do', 'prazo', 'produto', 'entregue', 'conforme', 'anuncio', 'volto', 'comprar', 'com', 'certeza']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"polarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4580834207550929,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kfold_polarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": -1,\n        \"max\": 10,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          5,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kfold_rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('olist.csv')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3c65j4VEfn0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "217f0ac7-5119-4f4c-d67e-1259b48e52c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "original_index              0\n",
              "review_text                 0\n",
              "review_text_processed       1\n",
              "review_text_tokenized       0\n",
              "polarity                 3665\n",
              "rating                      0\n",
              "kfold_polarity              0\n",
              "kfold_rating                0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>original_index</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_text</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_text_processed</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_text_tokenized</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>polarity</th>\n",
              "      <td>3665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rating</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>kfold_polarity</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>kfold_rating</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Linhas antes da limpeza: {df.shape[0]}\")\n",
        "df = df.dropna(subset=['review_text_tokenized', 'polarity'])\n",
        "print(f\"Linhas após a limpeza: {df.shape[0]}\")"
      ],
      "metadata": {
        "id": "-FR41nKcTpue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80c56113-9b7e-493e-c8f1-483f1a635ad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linhas antes da limpeza: 41744\n",
            "Linhas após a limpeza: 38079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_zlVPjPEqFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "087f8c56-428f-4235-e01f-2af3384df6c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinamento: 26656\n",
            "Validação: 3808\n",
            "Teste: 3808\n"
          ]
        }
      ],
      "source": [
        "train_data = df[(df['kfold_polarity'] >= 2) & (df['kfold_polarity'] <= 8)]\n",
        "val_data = df[df['kfold_polarity'] == 9]\n",
        "test_data = df[df['kfold_polarity'] == 1]\n",
        "\n",
        "print(f\"Treinamento: {len(train_data)}\")\n",
        "print(f\"Validação: {len(val_data)}\")\n",
        "print(f\"Teste: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZ4pfHqLF-k9"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrnJFkrhGDvd"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(texts):\n",
        "    return tokenizer(texts, padding=True, truncation=True, max_length=128)\n",
        "\n",
        "train_encodings = tokenize_function(train_data['review_text_tokenized'].tolist())\n",
        "val_encodings = tokenize_function(val_data['review_text_tokenized'].tolist())\n",
        "test_encodings = tokenize_function(test_data['review_text_tokenized'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_mKH2sgGPot"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from datasets import Dataset\n",
        "\n",
        "train_labels = torch.tensor(train_data['polarity'].values, dtype=torch.long)\n",
        "val_labels = torch.tensor(val_data['polarity'].values, dtype=torch.long)\n",
        "test_labels = torch.tensor(test_data['polarity'].values, dtype=torch.long)\n",
        "\n",
        "train_dataset = Dataset.from_dict({\n",
        "    'input_ids': train_encodings['input_ids'],\n",
        "    'attention_mask': train_encodings['attention_mask'],\n",
        "    'labels': train_labels\n",
        "})\n",
        "\n",
        "val_dataset = Dataset.from_dict({\n",
        "    'input_ids': val_encodings['input_ids'],\n",
        "    'attention_mask': val_encodings['attention_mask'],\n",
        "    'labels': val_labels\n",
        "})\n",
        "\n",
        "test_dataset = Dataset.from_dict({\n",
        "    'input_ids': test_encodings['input_ids'],\n",
        "    'attention_mask': test_encodings['attention_mask'],\n",
        "    'labels': test_labels\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdTqlPabGUvd"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "# Classificação binária (polaridade)\n",
        "model = BertForSequenceClassification.from_pretrained('neuralmind/bert-base-portuguese-cased', num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWdgczVyGYjl"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=1.2721865183729507e-05, #Anterior: 2e-5\n",
        "    per_device_train_batch_size=16, #Anterior: 16\n",
        "    per_device_eval_batch_size=64, #Anterior: 64\n",
        "    num_train_epochs=3, #Anterior: 2\n",
        "    weight_decay=0.11310079021892039, #Anterior: 0.01\n",
        "    gradient_accumulation_steps=1, #Anterior: 2\n",
        "    fp16=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tq2PRH5tGlet"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyqWdDp_Gnm9"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzPTcBSYG0JN"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import torch\n",
        "\n",
        "def compute_metrics(dataset):\n",
        "    predictions = trainer.predict(dataset)\n",
        "    preds = torch.argmax(torch.tensor(predictions.predictions), axis=1)\n",
        "    labels = dataset[\"labels\"]\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    report = classification_report(labels, preds, target_names=[\"Negativo\", \"Positivo\"])\n",
        "\n",
        "    print(f\"Acurácia: {accuracy:.4f}\")\n",
        "    print(\"Relatório de Classificação:\\n\", report)\n",
        "\n",
        "compute_metrics(test_dataset)"
      ],
      "metadata": {
        "id": "lIgi_pRhsHpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9pBE_tjG0it"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"./sentiment_model\")\n",
        "tokenizer.save_pretrained(\"./sentiment_model\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model.save_pretrained(\"/content/drive/MyDrive/sentiment_model\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/sentiment_model\")"
      ],
      "metadata": {
        "id": "Id2lDMC5ZLKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"./sentiment_model\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"./sentiment_model\")\n",
        "\n",
        "def predict_sentiment(texts):\n",
        "    encodings = tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "    outputs = model(**encodings)\n",
        "    predictions = outputs.logits.argmax(dim=-1)\n",
        "    return predictions\n",
        "\n",
        "textos = [\"Este úlitmo lançamento não foi legal\", \"Não podia ter comprado um produto melhor.\"]\n",
        "predictions = predict_sentiment(textos)\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "0DZ5OoTir_5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fazendo Fine-tuning dos Hiperparâmetros"
      ],
      "metadata": {
        "id": "d1PuE51VQsgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "X3amlhYpROYH",
        "outputId": "eed033a2-9a21-4fe6-fbf3-9f83a152cfde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.1-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.1 colorlog-6.9.0 optuna-4.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "import optuna\n",
        "\n",
        "def model_init():\n",
        "    return BertForSequenceClassification.from_pretrained(\n",
        "        'neuralmind/bert-base-portuguese-cased',\n",
        "        num_labels=2\n",
        "    )\n",
        "\n",
        "def hp_space(trial):\n",
        "    return {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True),\n",
        "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16, 32]),\n",
        "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 2, 4),\n",
        "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.3),\n",
        "        \"gradient_accumulation_steps\": trial.suggest_categorical(\"gradient_accumulation_steps\", [1, 2, 4]),\n",
        "    }\n",
        "\n",
        "optuna_args = TrainingArguments(\n",
        "    output_dir=\"./optuna_test\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    per_device_eval_batch_size=64,\n",
        "    fp16=True,\n",
        "    save_total_limit=1,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\"\n",
        ")\n",
        "\n",
        "optuna_trainer = Trainer(\n",
        "    model_init=model_init,\n",
        "    args=optuna_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")\n",
        "\n",
        "print(\"Iniciando busca de hiperparâmetros com Optuna...\")\n",
        "\n",
        "best_run = optuna_trainer.hyperparameter_search(\n",
        "    direction=\"maximize\",\n",
        "    n_trials=5,  # Você pode aumentar para mais testes\n",
        "    hp_space=hp_space,\n",
        "    backend=\"optuna\"\n",
        ")\n",
        "\n",
        "print(\"\\nMelhores hiperparâmetros encontrados:\")\n",
        "for param, value in best_run.hyperparameters.items():\n",
        "    print(f\"{param}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rDwUJ3OjQzXI",
        "outputId": "30909018-961a-4356-e5ff-a7e7a782770a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-05-26 02:26:43,939] A new study created in memory with name: no-name-8107899b-f2c6-47ff-bcaa-a8391a7e1ac7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando busca de hiperparâmetros com Optuna...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcleandersilva\u001b[0m (\u001b[33mcleandersilva-portal-puc-campinas\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250526_022653-ajt5boqa</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/ajt5boqa' target=\"_blank\">graceful-energy-8</a></strong> to <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/ajt5boqa' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/ajt5boqa</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1666' max='1666' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1666/1666 07:51, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.206600</td>\n",
              "      <td>0.158807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.128700</td>\n",
              "      <td>0.164498</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-26 02:34:50,355] Trial 0 finished with value: 0.1644984930753708 and parameters: {'learning_rate': 2.5897590035892957e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 2, 'weight_decay': 0.12786594774902446, 'gradient_accumulation_steps': 4}. Best is trial 0 with value: 0.1644984930753708.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁█</td></tr><tr><td>eval/runtime</td><td>▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▁</td></tr><tr><td>eval/steps_per_second</td><td>█▁</td></tr><tr><td>train/epoch</td><td>▁▃▄▇██</td></tr><tr><td>train/global_step</td><td>▁▃▄▇██</td></tr><tr><td>train/grad_norm</td><td>█▇▁</td></tr><tr><td>train/learning_rate</td><td>█▄▁</td></tr><tr><td>train/loss</td><td>█▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.1645</td></tr><tr><td>eval/runtime</td><td>6.0303</td></tr><tr><td>eval/samples_per_second</td><td>631.477</td></tr><tr><td>eval/steps_per_second</td><td>9.95</td></tr><tr><td>total_flos</td><td>3506744145838080.0</td></tr><tr><td>train/epoch</td><td>2</td></tr><tr><td>train/global_step</td><td>1666</td></tr><tr><td>train/grad_norm</td><td>0.64303</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1287</td></tr><tr><td>train_loss</td><td>0.16273</td></tr><tr><td>train_runtime</td><td>481.7048</td></tr><tr><td>train_samples_per_second</td><td>110.674</td></tr><tr><td>train_steps_per_second</td><td>3.459</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">graceful-energy-8</strong> at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/ajt5boqa' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/ajt5boqa</a><br> View project at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250526_022653-ajt5boqa/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250526_023452-bu9ej7kc</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/bu9ej7kc' target=\"_blank\">sparkling-capybara-9</a></strong> to <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/bu9ej7kc' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/bu9ej7kc</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='416' max='416' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [416/416 05:06, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.173142</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-26 02:40:02,152] Trial 1 finished with value: 0.17314240336418152 and parameters: {'learning_rate': 1.1572306976108192e-05, 'per_device_train_batch_size': 32, 'num_train_epochs': 2, 'weight_decay': 0.27942418129188995, 'gradient_accumulation_steps': 4}. Best is trial 1 with value: 0.17314240336418152.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▁</td></tr><tr><td>eval/runtime</td><td>█▁</td></tr><tr><td>eval/samples_per_second</td><td>▁█</td></tr><tr><td>eval/steps_per_second</td><td>▁█</td></tr><tr><td>train/epoch</td><td>▁██</td></tr><tr><td>train/global_step</td><td>▁██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.17314</td></tr><tr><td>eval/runtime</td><td>5.966</td></tr><tr><td>eval/samples_per_second</td><td>638.285</td></tr><tr><td>eval/steps_per_second</td><td>10.057</td></tr><tr><td>total_flos</td><td>3496219703623680.0</td></tr><tr><td>train/epoch</td><td>1.994</td></tr><tr><td>train/global_step</td><td>416</td></tr><tr><td>train_loss</td><td>0.21086</td></tr><tr><td>train_runtime</td><td>308.5801</td></tr><tr><td>train_samples_per_second</td><td>172.766</td></tr><tr><td>train_steps_per_second</td><td>1.348</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">sparkling-capybara-9</strong> at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/bu9ej7kc' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/bu9ej7kc</a><br> View project at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250526_023452-bu9ej7kc/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250526_024004-gflfpyxh</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/gflfpyxh' target=\"_blank\">upbeat-aardvark-10</a></strong> to <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/gflfpyxh' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/gflfpyxh</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4998' max='4998' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4998/4998 11:29, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.190800</td>\n",
              "      <td>0.181100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.149800</td>\n",
              "      <td>0.173250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.122400</td>\n",
              "      <td>0.200240</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-26 02:51:35,579] Trial 2 finished with value: 0.20023983716964722 and parameters: {'learning_rate': 1.2721865183729507e-05, 'per_device_train_batch_size': 16, 'num_train_epochs': 3, 'weight_decay': 0.11310079021892039, 'gradient_accumulation_steps': 1}. Best is trial 2 with value: 0.20023983716964722.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▃▁█</td></tr><tr><td>eval/runtime</td><td>█▄▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▅█</td></tr><tr><td>eval/steps_per_second</td><td>▁▄█</td></tr><tr><td>train/epoch</td><td>▁▂▃▃▃▄▅▅▆▆▇██</td></tr><tr><td>train/global_step</td><td>▁▂▃▃▃▄▅▅▆▆▇██</td></tr><tr><td>train/grad_norm</td><td>▂▆▄▂▁▃▁▁█</td></tr><tr><td>train/learning_rate</td><td>█▇▆▅▅▄▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▅▃▂▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.20024</td></tr><tr><td>eval/runtime</td><td>6.0333</td></tr><tr><td>eval/samples_per_second</td><td>631.167</td></tr><tr><td>eval/steps_per_second</td><td>9.945</td></tr><tr><td>total_flos</td><td>5260116218757120.0</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>4998</td></tr><tr><td>train/grad_norm</td><td>14.54717</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1224</td></tr><tr><td>train_loss</td><td>0.15903</td></tr><tr><td>train_runtime</td><td>690.5937</td></tr><tr><td>train_samples_per_second</td><td>115.796</td></tr><tr><td>train_steps_per_second</td><td>7.237</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">upbeat-aardvark-10</strong> at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/gflfpyxh' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/gflfpyxh</a><br> View project at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250526_024004-gflfpyxh/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250526_025137-6iqt5tre</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/6iqt5tre' target=\"_blank\">major-cosmos-11</a></strong> to <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/6iqt5tre' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/6iqt5tre</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2499' max='2499' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2499/2499 09:08, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.204800</td>\n",
              "      <td>0.164147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.127500</td>\n",
              "      <td>0.154048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.108400</td>\n",
              "      <td>0.188663</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-26 03:00:47,863] Trial 3 finished with value: 0.1886626034975052 and parameters: {'learning_rate': 3.9853543236151584e-05, 'per_device_train_batch_size': 32, 'num_train_epochs': 3, 'weight_decay': 0.0874112051962272, 'gradient_accumulation_steps': 1}. Best is trial 2 with value: 0.20023983716964722.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▃▁█</td></tr><tr><td>eval/runtime</td><td>▁▅█</td></tr><tr><td>eval/samples_per_second</td><td>█▄▁</td></tr><tr><td>eval/steps_per_second</td><td>█▄▁</td></tr><tr><td>train/epoch</td><td>▁▂▃▅▅▆██</td></tr><tr><td>train/global_step</td><td>▁▂▃▅▅▆██</td></tr><tr><td>train/grad_norm</td><td>█▇▁▆</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▅▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.18866</td></tr><tr><td>eval/runtime</td><td>6.0403</td></tr><tr><td>eval/samples_per_second</td><td>630.436</td></tr><tr><td>eval/steps_per_second</td><td>9.933</td></tr><tr><td>total_flos</td><td>5260116218757120.0</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>2499</td></tr><tr><td>train/grad_norm</td><td>1.12531</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.1084</td></tr><tr><td>train_loss</td><td>0.13824</td></tr><tr><td>train_runtime</td><td>549.6049</td></tr><tr><td>train_samples_per_second</td><td>145.501</td></tr><tr><td>train_steps_per_second</td><td>4.547</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">major-cosmos-11</strong> at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/6iqt5tre' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/6iqt5tre</a><br> View project at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250526_025137-6iqt5tre/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250526_030049-hm44mmv1</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/hm44mmv1' target=\"_blank\">glowing-wood-12</a></strong> to <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/hm44mmv1' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/hm44mmv1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1666' max='1666' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1666/1666 07:56, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.218000</td>\n",
              "      <td>0.162341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.138200</td>\n",
              "      <td>0.164295</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-26 03:08:48,711] Trial 4 finished with value: 0.1642954796552658 and parameters: {'learning_rate': 1.3720528430905662e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 2, 'weight_decay': 0.24199327150893538, 'gradient_accumulation_steps': 4}. Best is trial 2 with value: 0.20023983716964722.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Melhores hiperparâmetros encontrados:\n",
            "learning_rate: 1.2721865183729507e-05\n",
            "per_device_train_batch_size: 16\n",
            "num_train_epochs: 3\n",
            "weight_decay: 0.11310079021892039\n",
            "gradient_accumulation_steps: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Utilizando o Modelo e a API"
      ],
      "metadata": {
        "id": "Oi2LANNtHDhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fpdf"
      ],
      "metadata": {
        "id": "CUIGt1fR0CP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfba910b-f690-412b-cf01-fcd20d39eecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=25af2d0882f3a2815509c7ced48b376fba8956a16bd98c7deff7cc5ffe725443\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/66/bbda9866da446a72e206d6484cd97381cbc7859a7068541c36\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf\n",
            "Successfully installed fpdf-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "from fpdf import FPDF\n",
        "from datetime import datetime\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uOMeTGvEHG7o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3578584-453a-4fc8-f77e-26394b756e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ig_user_id = \"17841449666813574\"\n",
        "app_id = \"1750857045465243\"\n",
        "app_secret = \"3879b6aeb6718a852a5bed85f1ab5fde\"\n",
        "user_access_token = \"EAAY4ZASwZCWJsBO9DOETVck86K7likqssFJ88bX96jfn00zEr2QWY40D1kqpJ9BtfDtGMCwZBr2C1iYj7mVPTPSQjIZA5p3shN7WTPyyYB9xpBlCkvmz23uFrL6iTz15hUl0d7ZAGwcZA0jicA0j1yghUofENIClhf70xzMwlrbVvJb8b0SLyPg9fcUvK4Jwgw09kC2rplqc0Ds0H2mAZDZD\"\n",
        "\n",
        "url = f\"https://graph.facebook.com/v17.0/oauth/access_token?grant_type=fb_exchange_token&client_id={app_id}&client_secret={app_secret}&fb_exchange_token={user_access_token}\"\n",
        "response = requests.get(url)\n",
        "long_access_token = response.json()[\"access_token\"]\n",
        "\n",
        "base_url = f\"https://graph.facebook.com/v17.0/{ig_user_id}/media?fields=id,caption,timestamp&access_token={long_access_token}\"\n",
        "\n",
        "if not os.path.exists('graficos'):\n",
        "    os.makedirs('graficos')"
      ],
      "metadata": {
        "id": "EB4U_ShlIKa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def coletar_comentarios_por_publicacao():\n",
        "    publicacoes = []\n",
        "    response = requests.get(base_url)\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()['data']\n",
        "        for item in data:\n",
        "            media_id = item['id']\n",
        "            caption = item.get('caption', 'Sem legenda')\n",
        "            timestamp = item.get('timestamp', None)\n",
        "\n",
        "            comments_url = f'https://graph.facebook.com/v17.0/{media_id}/comments?fields=id,text,timestamp,username&access_token={long_access_token}'\n",
        "            comments_response = requests.get(comments_url)\n",
        "\n",
        "            comentarios = []\n",
        "            if comments_response.status_code == 200:\n",
        "                comments_data = comments_response.json().get('data', [])\n",
        "                comentarios = [comment['text'] for comment in comments_data]\n",
        "            else:\n",
        "                print(f'Erro ao buscar comentários da mídia {media_id}')\n",
        "\n",
        "            publicacoes.append({\n",
        "                'media_id': media_id,\n",
        "                'caption': caption,\n",
        "                'comentarios': comentarios,\n",
        "                'timestamp': timestamp\n",
        "            })\n",
        "    else:\n",
        "        print('Erro ao buscar mídias:', response.text)\n",
        "\n",
        "    return publicacoes"
      ],
      "metadata": {
        "id": "0WNEh0pEJIvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/sentiment_model\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"/content/drive/MyDrive/sentiment_model\")"
      ],
      "metadata": {
        "id": "zQbm1TV1Qrq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analisar_sentimentos(comentarios):\n",
        "    resultados = []\n",
        "    if comentarios:\n",
        "        encodings = tokenizer(comentarios, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**encodings)\n",
        "            predictions = outputs.logits.argmax(dim=-1)\n",
        "\n",
        "        for comentario, pred in zip(comentarios, predictions):\n",
        "            sentimento = 'Positivo' if pred.item() == 1 else 'Negativo'\n",
        "            resultados.append((comentario, sentimento))\n",
        "    return resultados"
      ],
      "metadata": {
        "id": "OesD4VvtQ7nY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calcular_metricas(resultados):\n",
        "    total = len(resultados)\n",
        "    positivos = sum(1 for _, s in resultados if s == 'Positivo')\n",
        "    negativos = total - positivos\n",
        "    porcentagem_positivos = positivos / total * 100 if total else 0\n",
        "    porcentagem_negativos = negativos / total * 100 if total else 0\n",
        "    return positivos, negativos, porcentagem_positivos, porcentagem_negativos"
      ],
      "metadata": {
        "id": "hhvnWPxuUOQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_grafico_publicacao(caption, positivos, negativos, media_id):\n",
        "    labels = ['Positivos', 'Negativos']\n",
        "    sizes = [positivos, negativos]\n",
        "    colors = ['#4CAF50', '#F44336']\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors)\n",
        "    ax.axis('equal')\n",
        "    plt.title(caption[:50] + '...')\n",
        "    caminho = f'graficos/{media_id}.png'\n",
        "    plt.savefig(caminho)\n",
        "    plt.close()\n",
        "    return caminho\n",
        "\n",
        "\"\"\"\n",
        "def gerar_grafico_geral(total_positivos, total_negativos):\n",
        "    labels = ['Positivos', 'Negativos']\n",
        "    sizes = [total_positivos, total_negativos]\n",
        "    colors = ['#4CAF50', '#F44336']\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors)\n",
        "    ax.axis('equal')\n",
        "    plt.title('Distribuição Geral dos Sentimentos')\n",
        "    caminho = 'graficos/geral.png'\n",
        "    plt.savefig(caminho)\n",
        "    plt.close()\n",
        "    return caminho\n",
        "\"\"\"\n",
        "\n",
        "def gerar_grafico_temporal(resultados_temporais):\n",
        "    if not resultados_temporais:\n",
        "        return None\n",
        "\n",
        "    resultados_ordenados = sorted(resultados_temporais, key=lambda x: x['data'])\n",
        "\n",
        "    datas = [\n",
        "      datetime.strptime(item['data'], '%Y-%m-%dT%H:%M:%S%z').strftime('%d/%m/%Y %H:%M')\n",
        "      for item in resultados_ordenados\n",
        "    ]\n",
        "\n",
        "    porcentagens = [item['pct_positivos'] for item in resultados_ordenados]\n",
        "    legends = [item['caption'][:30] + '...' if len(item['caption']) > 30 else item['caption'] for item in resultados_ordenados]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    ax.plot(datas, porcentagens, marker='o', color='#2196F3', linestyle='-')\n",
        "\n",
        "    for i, txt in enumerate(legends):\n",
        "        ax.annotate(txt, (i, porcentagens[i]), textcoords=\"offset points\", xytext=(0,10),\n",
        "                    ha='center', fontsize=8, rotation=45)\n",
        "\n",
        "    ax.set_xticks(datas)\n",
        "    ax.set_xticklabels(datas, rotation=45, ha='right', fontsize=8)\n",
        "\n",
        "    ax.set_title('Evolução da Avaliação das Publicações ao Longo do Tempo')\n",
        "    ax.set_xlabel('Data da Publicação')\n",
        "    ax.set_ylabel('% de Comentários Positivos')\n",
        "    ax.set_ylim(0, 100)\n",
        "    ax.grid(True)\n",
        "\n",
        "    caminho = 'graficos/grafico_temporal.png'\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(caminho)\n",
        "    plt.close()\n",
        "    return caminho\n"
      ],
      "metadata": {
        "id": "cTDDtRQnUSiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Função utilizada na solução provisória para os emojis dando erro ao gerar o pdf\n",
        "def remove_emojis(text):\n",
        "    return text.encode('latin-1', 'ignore').decode('latin-1')"
      ],
      "metadata": {
        "id": "BKsIFrFaIWQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PDFRelatorio(FPDF):\n",
        "    def header(self):\n",
        "        self.set_font('Arial', 'B', 16)\n",
        "        self.cell(0, 10, 'Relatório de Análise de Sentimentos - Instagram', 0, 1, 'C')\n",
        "        self.ln(10)\n",
        "\n",
        "    def footer(self):\n",
        "        self.set_y(-15)\n",
        "        self.set_font('Arial', 'I', 8)\n",
        "        self.cell(0, 10, f'Página {self.page_no()}', 0, 0, 'C')\n",
        "\n",
        "    def add_publicacao(self, caption, positivos, negativos, porcentagem_positivos, porcentagem_negativos, grafico_path):\n",
        "        self.set_font('Arial', 'B', 12)\n",
        "        #Solução provisória para os emojis\n",
        "        self.multi_cell(0, 10, remove_emojis(caption))\n",
        "        self.set_font('Arial', '', 12)\n",
        "        self.cell(0, 10, f'Positivos: {positivos} ({porcentagem_positivos:.2f}%)', 0, 1)\n",
        "        self.cell(0, 10, f'Negativos: {negativos} ({porcentagem_negativos:.2f}%)', 0, 1)\n",
        "        self.ln(3)\n",
        "        self.image(grafico_path, w=150)\n",
        "        self.ln(10)\n",
        "\n",
        "    def add_conclusao_geral(self, total_positivos, total_negativos, pct_positivos, pct_negativos, grafico_path):\n",
        "        self.add_page()\n",
        "        self.set_font('Arial', 'B', 14)\n",
        "        self.cell(0, 10, 'Resumo Geral', 0, 1, 'C')\n",
        "        self.ln(5)\n",
        "        self.set_font('Arial', '', 12)\n",
        "        self.cell(0, 10, f'Total de Comentários Positivos: {total_positivos} ({pct_positivos:.2f}%)', 0, 1)\n",
        "        self.cell(0, 10, f'Total de Comentários Negativos: {total_negativos} ({pct_negativos:.2f}%)', 0, 1)\n",
        "        self.ln(5)\n",
        "        self.image(grafico_path, w=150)\n",
        "        self.ln(10)\n",
        "\n",
        "        conclusao = 'Conclusão geral: '\n",
        "        if pct_positivos > 70:\n",
        "            conclusao += 'O perfil está muito bem avaliado!'\n",
        "        elif pct_positivos > 40:\n",
        "            conclusao += 'O perfil está com avaliação mista.'\n",
        "        else:\n",
        "            conclusao += 'O perfil está sendo mal avaliado.'\n",
        "\n",
        "        self.multi_cell(0, 10, conclusao)"
      ],
      "metadata": {
        "id": "piZ9pp2xUYLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "publicacoes = coletar_comentarios_por_publicacao()\n",
        "pdf = PDFRelatorio()\n",
        "pdf.add_page()\n",
        "\n",
        "print(publicacoes)\n",
        "\n",
        "total_resultados = []\n",
        "resultados_temporais = []\n",
        "\n",
        "total_positivos = 0\n",
        "total_negativos = 0\n",
        "\n",
        "for publicacao in publicacoes:\n",
        "    comentarios = publicacao['comentarios']\n",
        "    caption = publicacao['caption']\n",
        "    media_id = publicacao['media_id']\n",
        "\n",
        "    if comentarios:\n",
        "        resultados = analisar_sentimentos(comentarios)\n",
        "        positivos, negativos, pct_positivos, pct_negativos = calcular_metricas(resultados)\n",
        "        grafico_path = gerar_grafico_publicacao(caption, positivos, negativos, media_id)\n",
        "\n",
        "        pdf.add_publicacao(caption, positivos, negativos, pct_positivos, pct_negativos, grafico_path)\n",
        "\n",
        "        total_positivos += positivos\n",
        "        total_negativos += negativos\n",
        "        total_resultados.extend(resultados)\n",
        "\n",
        "        resultados_temporais.append({\n",
        "            'data': publicacao['timestamp'],\n",
        "            'pct_positivos': pct_positivos,\n",
        "            'caption': caption\n",
        "        })\n",
        "\n",
        "grafico_temporal_path = gerar_grafico_temporal(resultados_temporais)\n",
        "pct_total_positivos = total_positivos / (total_positivos + total_negativos) * 100 if (total_positivos + total_negativos) else 0\n",
        "pct_total_negativos = 100 - pct_total_positivos\n",
        "\n",
        "pdf.add_conclusao_geral(total_positivos, total_negativos, pct_total_positivos, pct_total_negativos, grafico_temporal_path)\n",
        "\n",
        "pdf.output('relatorio_sentimentos_instagram.pdf')"
      ],
      "metadata": {
        "id": "v0G3wOG3Uc3R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "180c81d9-dbfa-4214-bf19-8b31c6c13d6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'media_id': '17982061616675940', 'caption': 'O que esse negócio de I.A tá ficando bom em foto é brincadeira 😳', 'comentarios': ['Que lindosss❤️❤️', '❤️❤️❤️', 'A IA nao colocou aliança na sua foto 😠', 'Amei!! ❤️❤️', 'ta roubando o emprego do vasco', 'Legal que na terceira foto a Le não tá de olho fechado mas a IA entendeu que tava hahahaha', 'A Porsche virou fusca kkkkkkkk', 'show de bola🙌❤️', 'parece o dj oreia', 'ficou parecido irmão 👏👏'], 'timestamp': '2025-03-31T15:00:00+0000'}, {'media_id': '18487181953049729', 'caption': 'Obrigado por essa vista maravilhosa!! 🥹', 'comentarios': ['Kkkkkkkkkkkkk', '😂😂😂😂😂', '👏👏👏muito  bom', 'O que importa é a companhia!!', '😂😂😂', 'Nuussssss......deu ate medo 😂😂'], 'timestamp': '2025-01-06T16:19:11+0000'}, {'media_id': '18044393930191067', 'caption': 'Eu e você, você e eu ♥️', 'comentarios': ['👏👏👏👏👏👏👏👏👏', '🔥🔥🔥🔥🔥🔥kkkkk', '👏👏👏👏👏🔥🔥🔥🔥', '💘💘💘💘', 'linducos', 'Lindos amooooo ❤️❤️❤️', 'Seus lindos ❤️❤️', 'Lindicos', 'Meu tudinho', 'Te amo muito lindeza❤️❤️❤️'], 'timestamp': '2025-01-03T22:00:00+0000'}, {'media_id': '17942893244936864', 'caption': 'Como é bom viajar! 😂😂😂', 'comentarios': ['Rindo de nervoso', 'KKKKKKKKKK'], 'timestamp': '2025-01-01T15:14:17+0000'}, {'media_id': '18078186811539973', 'caption': 'Mais alguém aí não aguenta mais?! 😅😩', 'comentarios': ['😂😂😂', 'nao tanka 1 ano de clt', 'Estou em SAN Martin de los Andes . Frio p/ cacete', 'Muito eu 😂😂', 'Afinal a viagem foi legal ou não?'], 'timestamp': '2024-12-31T15:00:00+0000'}, {'media_id': '17864298684295236', 'caption': 'Como é esperar seu voo na Sala Vip da @nomadglobalapp? Vem comigo que eu te mostro! 💛\\n\\nEu e a minha namorada decidimos passar alguns dias fora do país e aproveitamos para esperar nosso voo na Sala Vio da Nomad no aeroporto de Guarulhos, não podia ser diferente, né?!\\n\\nQuer poder ter acesso a tudo isso que eu te mostrei no vídeo? Crie a sua conta internacional Nomad hoje e utilize o cupom STOCCO para garantir até 20 dólares de cashback!* 🤩\\n\\nNão perde tempo, vem ser Nomad! 💛\\n\\n*A sala vip é liberada para clientes Nível 2 Nomad e você pode ganhar até 20 dólares de cashback ao realizar a sua primeira operação de câmbio em até 15 dias da abertura da conta.\\n\\npubli', 'comentarios': ['👏👏👏👏👏👏', 'uauuuu', 'uauuuu!', 'Experiência incrível!  Muito obrigada @nomadglobalapp por todo o carinho e conforto! 💛💛💛', 'Salinha sinistra 🔥', '👏👏👏 picaaaaaaa', 'nomad > binomo @eversonzoio', 'amassaria essa mesa inteira', 'muiiito boa! obrigado @nomadglobalapp', 'Top demais 👏', 'Top hein 👏👏😍😍 ..... pode ja me dar essa manteiga de cacau q ganhou pq sei q nao usa 😁😁😁😁', 'Chocolate pra dormir eh amais kkkkkkkk', 'que gostosuras 👏', 'que chique achei melhor que a do mastercard'], 'timestamp': '2024-12-30T22:15:11+0000'}, {'media_id': '17999663492706726', 'caption': 'una coronita porfavorzito', 'comentarios': ['Na  ária👏👏👏👏', 'lindao ❤️', '👏👏👏👏', '👏👏👏👏', 'tão bonitinho, nem parece o ber', 'chiqueeee', 'ta mal 👏👏', 'uau bidus', 'acesso vip🔥', 'Uauuuuu hermoso ❤️😍😂😂😂', 'Que menino mais lindo!!!❤️❤️', 'Kkkk', 'Aindaaaa 😛✌🏻', 'Que hombre!', 'vuelasita também tema amorsito kkkkkk', 'manager 🔥', '😍😍😍😍😍😍😍😍😍😍😍😍😍', 'Te amo gostosito👏❤️', 'Uau gatinho'], 'timestamp': '2024-12-29T22:21:19+0000'}, {'media_id': '18082561189564865', 'caption': 'é nosso jeitinho de viajar, tá errado? 🤪 #reelsinstagram #viagem #reels', 'comentarios': ['Muito  legau  o  passeio', 'Isso é muito a gente kkkkk @maatheusvilela_', 'KKKKKKKKKKKKKKKK', 'Tb sou assim', '😂😂😂😂😂', '👏👏👏👏👏', 'Kkkkk', 'Kkkkkkkkk adorei', 'Kkkkkkkkkkkkk jovens jovens', 'Amei nossa viagem!', 'Eu devo ser a mãe de vocês…..😂😂', 'Kkkkkkkkkkkkk'], 'timestamp': '2024-12-28T22:24:36+0000'}, {'media_id': '17858794836302414', 'caption': '06.12 ♥️ postando só as nossas melhores fotos', 'comentarios': ['muito bom ver o amor de vcs!❤️❤️', '😍😍😍', 'Kkkkkkkkkk Deus abençoe vocês!! Feliz 1 ano! Amo vcs ❤️❤️❤️', 'Na ARIA 👏👏👏', 'Meus amores ❤️❤️', 'Tudinho', 'Te amo tanto❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️', 'KKKKKKKKKKKK', 'Meu irmão bom dia Deus abençoe perdão pelo horário por gentileza eu posso tomar um minutinho da sua atenção'], 'timestamp': '2024-12-06T03:34:31+0000'}, {'media_id': '18321180199084064', 'caption': 'é sério levem eles!!!', 'comentarios': ['😂😂😂😂😂😂', 'KKKKKKKKKK ops'], 'timestamp': '2024-11-12T15:00:00+0000'}, {'media_id': '17910494946020255', 'caption': 'Achei perdido nos rascunhos! Tinha esquecido de postar essa nossa viagem para Brotas!! 😍❤️ #reels #reelsinstagram #viagem #casal #trip', 'comentarios': ['Ê  isso ai  na aria', 'lindossss ❤️', 'Q gays', '😍😍😍😍😍😍', 'Lindos ❤️❤️❤️❤️', '😍😍😍', 'Lindos ❤️❤️❤️❤️ amoooo', 'Lindos demais', 'Ahhh que lindos!!!!❤️'], 'timestamp': '2024-11-06T20:33:22+0000'}, {'media_id': '18072248605579629', 'caption': 'fim de semana em noronha, tá liberado?', 'comentarios': ['Fotao ber!!! ❤️❤️❤️', 'a loc tá errada, devia estar “localiza aí comédia” 🎭', 'vive bem e se diverte 👏👏', 'Te amo❤️', 'Que tumblr👏👏'], 'timestamp': '2024-10-06T16:16:52+0000'}, {'media_id': '18056109424766756', 'caption': 'Eu adorava quando isso acontecia KKKKKKKK', 'comentarios': ['😂😂😂😂😂😂😂😂😂', 'KKKKKKKKKKKKK', 'KKKKKKKKKKKKK', 'KKKKKKKKKKKKKKKKKK', 'IGUALL KAKAKKAKAKKAK', 'É assim mesmo 😂😂👏👏'], 'timestamp': '2024-09-14T15:00:00+0000'}, {'media_id': '18057739990689080', 'caption': 'Não era pra VOCÊ  tá dormindo não amigão! 🤦🏻\\u200d♂️', 'comentarios': ['i a música? descobriu o nome?', 'e o nome da música?', 'e o nome da música pae?', 'qual nome da música, meu patrão?', 'qual nome da música, meu campeão?', 'E so  freiar  que  acorda', '😂😂😂😂', 'qual nome da música, meu consagrado?', 'sair dps do almoço é foda', '😂😂😂', 'Pior que ja peguei uber com esse cara uma vez, toda vez isso, irresponsabilidade imensa!'], 'timestamp': '2024-09-13T15:00:00+0000'}, {'media_id': '17935237541793963', 'caption': 'Você pode não falar inglês, mas a Nomad fala por você.\\nAbra sua conta Nomad e viaje pelo mundo economizando com a cotação do câmbio comercial.\\nE aplicando o código de convidado STOCCO na abertura da conta, você ganha até 20 dólares de cashback na sua primeira operação de câmbio feita em até 15 dias da abertura da conta. É só clicar no link da BIO 😉\\n \\n - Aceito em mais de 180 países\\n- Atendimento 100% em português\\n- IOF de 1,1% muito mais barato do que cartão de crédito internacional - Cotação do câmbio comercial\\n- Segurança de não precisar levar dinheiro em espécie\\n- Cartão de débito internacional virtual e físico\\n\\n*publi*', 'comentarios': ['Vai  pra ARGENTINA', 'Hahaha me divirto com seis posts!!! Muito dez👏👏👏👏👏', '@leishikawavilela como assim vc tirou os cílios le????', '@leishikawavilela , vc cortou o cabelo? Tá meio diferente', 'Leticia ta tomando trembo', 'Muito bom!!! 😂😂😂', 'A Letícia 👩🏻😂😂😂😂', 'eu te amooooooo nomad', 'a leticia de camisa do brasil fica diferente ne', 'Bela publi', 'Mlk tu tá muito ator KKKKKKKKK', 'letícia tá diferente', 'A Nomad é mesmo incrível!! 😍😍😍'], 'timestamp': '2024-09-12T15:07:30+0000'}, {'media_id': '18054918988764426', 'caption': 'Manda para aquele amigo que passou aqui pra retirar o título 👀👀', 'comentarios': ['@pedro.eloii_', '@pedro.eloii_', '@pedro.eloii_'], 'timestamp': '2024-09-11T21:00:00+0000'}, {'media_id': '18132364018367165', 'caption': 'É SEMPRE assim kkkkkk', 'comentarios': ['Muito bom', 'As resenhas no Le carnê de peixê eram as melhores', 'batataixxxxxx', 'Kkkkkkk muito bom!👏', 'Ator e os krl', '🍸', 'saudades daquele 15 de setembro quando a gente saboreou aquela lagosta e aquele baião de dois no Témõs Lagostą Camarón', 'Vou te contratar .... rsrrs', 'Que isso gnt!??? Kkkkk', 'meu detetive preferido😮\\u200d💨😮\\u200d💨😮\\u200d💨', 'eu amo', 'é sempre assimmmmm kkkkkkkkkk', 'meu sonho e ir pra chupinguaia', 'Chupinguaia ta pocando em 😂👏', 'Peçanha é fod@ 😂', 'Igualzin AKAKKAKAAKAKAK'], 'timestamp': '2024-09-09T21:00:00+0000'}, {'media_id': '18032017490469795', 'caption': 'Eu não aguento mais essa vida do triguinho 😫😫 ib: @_eu_lucaxx', 'comentarios': ['Joga mais  20  contos', '😂😂😂', '😂😂😂', 'gera jogar mais 20', 'plataforma ta pagando muitoooo', 'mkkkkkkkkkkkkkkkkk', 'Só mais 20tin vai KAKAKAK', 'capeta com essa cara'], 'timestamp': '2024-09-07T15:00:00+0000'}, {'media_id': '17842787517309690', 'caption': 'Pov: eu sou o vizinho 😅', 'comentarios': ['KAKAKAKKAKA', 'kkkkkkkkkkkkkk sempre assim', 'todo dia isso'], 'timestamp': '2024-09-05T15:39:58+0000'}, {'media_id': '18460250785028287', 'caption': 'Eu admito, sou viciado em mentir 🙋🏻\\u200d♂️', 'comentarios': ['😂😂😂😂😂', 'Kkkkk adorei as mentiras😂😂😂😂', 'A Demi HAHAHAHAHAHAHAHAHA', 'parabens', 'KKKKKKKKK pior q eu ri desse', '😂😂', 'Guerra em Goiás foi foda kkkkkkkk', 'demi lovato kkkkkkkkkkkkkkkk', '😂😂', 'ta foda, Demi', '😂😂😂', 'KKKKKKKKKKKKKKKKKK', '📍Chupinguaia - RO', 'pior que a historia verdadeira da placa é triste', 'KAKAKAKAKAKAK', 'Que isso demo lovato, em chupinguaia é osso 😂😂😂'], 'timestamp': '2024-09-04T15:00:00+0000'}, {'media_id': '18024718721110765', 'caption': 'Todo mundo conhece alguém assim KKKKKKKKKK', 'comentarios': ['Reclama pro xandao 😂', '😢', '😮😮', 'KKKKKKKKKKKKKK', 'mds', 'KKKKKKKKKKKKKKKKKKKK SOS', '😂😂😂', '@gabipianca', '@justochh'], 'timestamp': '2024-08-31T20:29:42+0000'}, {'media_id': '18002749895419060', 'caption': 'Sabe aquela fome que bate de madrugada?! \\n\\nA BOLD é a barrinha perfeita para te salvar dessa situação terrível! É só esquentar ela por 15 a 20 segundos no microondas e tá pronta! Fica uma delícia!\\n\\nGaranta as suas barrinhas utilizando o cupom STOCCO na hora do pagamento ou clicando no link da minha bio! 😍 Experimenta por aí @boldsnacks\\n\\n*publi* #boldsnacks #boldsalva', 'comentarios': ['Isso não me slknents de madrugada não... aliás  geralmente nem como nada de madrugada', 'Altão e não viu essa linda barrinha emcima da geladeira, abre o olho malandro', 'fica bem suculenta quando coloca no microondas, amo!!', 'eu amoooo essa barrinha!!🤤🤤🤤', '@gabi2cordeiro assista isso 😮😮😮', 'que delícia! a barra tambem parece super boa.', 'A melhor q ja comi na vida 😋😋', 'Delícia!', 'Essa barrinha da Bold é muito boa!!!! Ja comprei a minha com desconto!!!', 'que fome de bold 😋'], 'timestamp': '2024-07-31T15:00:00+0000'}, {'media_id': '17928069383795956', 'caption': 'Quem aí também pegaria só a barrinha da BOLD?? 😅\\n\\nA BOLD é uma barrinha rica em proteína e muito sabor. Perfeita pra quem quer se alimentar de forma saudável, praticar exercícios ou só comer um snack gostoso mesmo!\\n\\nGaranta as suas barrinhas utilizando o cupom STOCCO na hora do pagamento ou clicando no link da minha bio! 😍 Experimenta por aí! 😋 @boldsnacks \\n\\n*publi* #boldsnacks #boldsalva', 'comentarios': ['bold é vida 🙌', 'ISSO  QUE  E GOSTAR  DR  CHOCOLAYE', 'O resto do presente manda aqui kkkk', 'fodaaaaa', 'Adorooooooo 👏👏👏👏', 'minha favorita!!! ❤️❤️❤️', 'amei o presente🥰🥰🥰', 'Kkkkkkk', 'Gosto da Brownie', 'opa percebi que seu perfil se qualifica para participar da', 'kkkkkk é disso que elas gostam', 'Gênio kkkkkkkk', 'Kkkkkkkkkkkkk', 'pior que a barra e legal mesmo!', '😂👏', 'Essa ai é a top 2 pra mim, so perde pra de', 'KKKKKKKKKKKKKKKKKKKKK eu amei!', 'diferenciado', 'Genio do mkt', 'Eu teria escolhido igual! 😋😋😋', 'Kkkkkkkkkkk muita humildade', 'Kkkkk essa barrinha é boa mesmo!!!!'], 'timestamp': '2024-07-27T15:00:00+0000'}, {'media_id': '18053683015687917', 'caption': \"McDonald's 1 Estrela VS McDonald's 5 Estrelas! 🍔⭐️\", 'comentarios': ['comi muito nesse mc às quartas feiras', 'Moito  BOM', 'Onde vocês vem as a avaliações?', 'Coragem ..tô fora', 'Eu acho que eu ia pular de felicidade', 'Todos é 5 estrela pq é de SJC 😂😂😂', 'é o neox que te copia, ou voce que copia o neox?', '@mcdonalds_br', '👏👏👏👏', 'quero um combro do big mc', '😋😋😋', 'prefiro o girafas, seu restaurante preferido!!', 'Nem sabia q existia essa diferença entre os MCs ..... Top o video !!👏👏', 'e cadê minha coquinha ein???', 'GARANTA AS SUAS BARRINHAS DA BOLD COM 10% OFF CLICANDO NO LINK DA MINHA BIO! 😍', 'avalia o bobs na proxima', 'slc esse segundo mc eu nunca fui', '🍔', 'Bk eh melhor', 'Mc Donald’s só é 5 estrelas, quando tem Pokemon no Mc Lanche Feliz. \\nBeijos.', 'slk mczinho deixou a desejar', 'Top 😂👏'], 'timestamp': '2024-07-26T15:00:00+0000'}, {'media_id': '18017206481183008', 'caption': 'Eu Me Tranquei Nesse Quarto! 😱', 'comentarios': ['kkkk eu já iria começar pela soneca 😂😂😂😂', 'Se nao dormisse nao perderia a hs 😂😂', 'só vc msm', '😂😂', 'só dormeeee', 'sem noção!!', 'A soneca te lascou kkkk', 'Ocio criativo!😂', '😮😮😮😮', 'Irmão até o fim do ano o milhão vem, seu conteúdo tá fod@@@ ❤️🔥', 'eu nao me trancaria no quarto do vasco', 'louco sempre foi né', '😂😂😂', 'Caramba, muito massa', 'A soneca te fudeu'], 'timestamp': '2024-07-24T15:00:00+0000'}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-34a78c349540>:11: UserWarning: Glyph 129401 (\\N{FACE HOLDING BACK TEARS}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(caminho)\n",
            "<ipython-input-8-34a78c349540>:11: UserWarning: Glyph 129322 (\\N{GRINNING FACE WITH ONE LARGE AND ONE SMALL EYE}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(caminho)\n",
            "<ipython-input-8-34a78c349540>:11: UserWarning: Glyph 129318 (\\N{FACE PALM}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(caminho)\n",
            "<ipython-input-8-34a78c349540>:11: UserWarning: Glyph 127995 (\\N{EMOJI MODIFIER FITZPATRICK TYPE-1-2}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(caminho)\n",
            "<ipython-input-8-34a78c349540>:11: UserWarning: Glyph 128587 (\\N{HAPPY PERSON RAISING ONE HAND}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(caminho)\n",
            "<ipython-input-8-34a78c349540>:11: UserWarning: Glyph 127828 (\\N{HAMBURGER}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(caminho)\n",
            "<ipython-input-8-34a78c349540>:11: UserWarning: Glyph 11088 (\\N{WHITE MEDIUM STAR}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(caminho)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}