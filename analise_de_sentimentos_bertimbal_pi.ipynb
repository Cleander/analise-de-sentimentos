{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cleander/analise-de-sentimentos/blob/main/analise_de_sentimentos_bertimbal_pi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Análise de Sentimentos - PI 5"
      ],
      "metadata": {
        "id": "WZV2KoU_4t_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Treinando o Modelo"
      ],
      "metadata": {
        "id": "nzkTk2qD4SCj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIwE2ItxDpiE"
      },
      "outputs": [],
      "source": [
        "pip install transformers datasets torch pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j8mwsLQlDp30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "cc92fdab-eea8-4747-93ae-38b4de510d58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   original_index                                        review_text  \\\n",
              "0           97262             Perfeito....chegou antes do prazo.....   \n",
              "1           72931  Foi uma ótima compra! Chegou antes mesmo do pr...   \n",
              "2           19659     Recebi muito rapido e um otimo custo beneficio   \n",
              "3           43054                                          Recomendo   \n",
              "4           59202  Só veio uma capa comprei 3 aí paguei. Mais de ...   \n",
              "\n",
              "                               review_text_processed  \\\n",
              "0             perfeito....chegou antes do prazo.....   \n",
              "1  foi uma otima compra! chegou antes mesmo do pr...   \n",
              "2     recebi muito rapido e um otimo custo beneficio   \n",
              "3                                          recomendo   \n",
              "4  so veio uma capa comprei 3 ai paguei. mais de ...   \n",
              "\n",
              "                               review_text_tokenized  polarity  rating  \\\n",
              "0     ['perfeito', 'chegou', 'antes', 'do', 'prazo']       1.0       5   \n",
              "1  ['foi', 'uma', 'otima', 'compra', 'chegou', 'a...       1.0       5   \n",
              "2  ['recebi', 'muito', 'rapido', 'um', 'otimo', '...       1.0       5   \n",
              "3                                      ['recomendo']       1.0       5   \n",
              "4  ['so', 'veio', 'uma', 'capa', 'comprei', 'ai',...       0.0       1   \n",
              "\n",
              "   kfold_polarity  kfold_rating  \n",
              "0               1             1  \n",
              "1               1             1  \n",
              "2               1             1  \n",
              "3               1             1  \n",
              "4               1             1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a872fc7-597b-4cdf-8ffb-09885027e5c3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_index</th>\n",
              "      <th>review_text</th>\n",
              "      <th>review_text_processed</th>\n",
              "      <th>review_text_tokenized</th>\n",
              "      <th>polarity</th>\n",
              "      <th>rating</th>\n",
              "      <th>kfold_polarity</th>\n",
              "      <th>kfold_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>97262</td>\n",
              "      <td>Perfeito....chegou antes do prazo.....</td>\n",
              "      <td>perfeito....chegou antes do prazo.....</td>\n",
              "      <td>['perfeito', 'chegou', 'antes', 'do', 'prazo']</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>72931</td>\n",
              "      <td>Foi uma ótima compra! Chegou antes mesmo do pr...</td>\n",
              "      <td>foi uma otima compra! chegou antes mesmo do pr...</td>\n",
              "      <td>['foi', 'uma', 'otima', 'compra', 'chegou', 'a...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19659</td>\n",
              "      <td>Recebi muito rapido e um otimo custo beneficio</td>\n",
              "      <td>recebi muito rapido e um otimo custo beneficio</td>\n",
              "      <td>['recebi', 'muito', 'rapido', 'um', 'otimo', '...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43054</td>\n",
              "      <td>Recomendo</td>\n",
              "      <td>recomendo</td>\n",
              "      <td>['recomendo']</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>59202</td>\n",
              "      <td>Só veio uma capa comprei 3 aí paguei. Mais de ...</td>\n",
              "      <td>so veio uma capa comprei 3 ai paguei. mais de ...</td>\n",
              "      <td>['so', 'veio', 'uma', 'capa', 'comprei', 'ai',...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a872fc7-597b-4cdf-8ffb-09885027e5c3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8a872fc7-597b-4cdf-8ffb-09885027e5c3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8a872fc7-597b-4cdf-8ffb-09885027e5c3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-89ead06a-b2dd-432a-859c-7952ce63a4de\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-89ead06a-b2dd-432a-859c-7952ce63a4de')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-89ead06a-b2dd-432a-859c-7952ce63a4de button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 41744,\n  \"fields\": [\n    {\n      \"column\": \"original_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28894,\n        \"min\": 3,\n        \"max\": 99999,\n        \"num_unique_values\": 41744,\n        \"samples\": [\n          57902,\n          44445,\n          40301\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 36920,\n        \"samples\": [\n          \"Compra e entrega sem problemas\",\n          \"\\u00d3timo produto entrega r\\u00e1pida \",\n          \"Comprei um atuador de freio para minha maquina...paguei a vista...fiquei quase 20 dias esperando paguei o frete...e quando recebo o produto uma decep\\u00e7\\u00e3o...mandaram produto errado...enviaram uma placa \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_text_processed\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 36190,\n        \"samples\": [\n          \"chegou rapido, lacrado e bem embalado\",\n          \"produto com qualidade. recomendo a compra, esse e o segundo produto que compro.\",\n          \"chegou antes do esperado e o produto e lindo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_text_tokenized\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33929,\n        \"samples\": [\n          \"['faltou', 'colocar', 'no', 'pedido', 'nome', 'completo', 'deixei', 'endereco', 'de', 'onde', 'trabalho', 'para', 'entrega', 'tem', 'pessoas', 'com', 'mesmo', 'nome']\",\n          \"['produto', 'recebido', 'no', 'prazo']\",\n          \"['entrega', 'bemmm', 'antes', 'do', 'prazo', 'produto', 'entregue', 'conforme', 'anuncio', 'volto', 'comprar', 'com', 'certeza']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"polarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4580834207550929,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kfold_polarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": -1,\n        \"max\": 10,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          5,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kfold_rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('olist.csv')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "D3c65j4VEfn0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "ee252dcc-a2a0-4f3a-bb40-333d81de506e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "original_index              0\n",
              "review_text                 0\n",
              "review_text_processed       1\n",
              "review_text_tokenized       0\n",
              "polarity                 3665\n",
              "rating                      0\n",
              "kfold_polarity              0\n",
              "kfold_rating                0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>original_index</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_text</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_text_processed</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_text_tokenized</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>polarity</th>\n",
              "      <td>3665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rating</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>kfold_polarity</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>kfold_rating</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Linhas antes da limpeza: {df.shape[0]}\")\n",
        "df = df.dropna(subset=['review_text_tokenized', 'polarity'])\n",
        "print(f\"Linhas após a limpeza: {df.shape[0]}\")"
      ],
      "metadata": {
        "id": "-FR41nKcTpue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dc65caa-a21d-4487-f8e0-429372ef7441"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linhas antes da limpeza: 41744\n",
            "Linhas após a limpeza: 38079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "U_zlVPjPEqFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76382bcd-efa5-42a9-e810-34eb674effa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinamento: 26656\n",
            "Validação: 3808\n",
            "Teste: 3808\n"
          ]
        }
      ],
      "source": [
        "train_data = df[(df['kfold_polarity'] >= 2) & (df['kfold_polarity'] <= 8)]\n",
        "val_data = df[df['kfold_polarity'] == 9]\n",
        "test_data = df[df['kfold_polarity'] == 1]\n",
        "\n",
        "print(f\"Treinamento: {len(train_data)}\")\n",
        "print(f\"Validação: {len(val_data)}\")\n",
        "print(f\"Teste: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZ4pfHqLF-k9"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PrnJFkrhGDvd"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(texts):\n",
        "    return tokenizer(texts, padding=True, truncation=True, max_length=128)\n",
        "\n",
        "train_encodings = tokenize_function(train_data['review_text_tokenized'].tolist())\n",
        "val_encodings = tokenize_function(val_data['review_text_tokenized'].tolist())\n",
        "test_encodings = tokenize_function(test_data['review_text_tokenized'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "H_mKH2sgGPot"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from datasets import Dataset\n",
        "\n",
        "train_labels = torch.tensor(train_data['polarity'].values, dtype=torch.long)\n",
        "val_labels = torch.tensor(val_data['polarity'].values, dtype=torch.long)\n",
        "test_labels = torch.tensor(test_data['polarity'].values, dtype=torch.long)\n",
        "\n",
        "train_dataset = Dataset.from_dict({\n",
        "    'input_ids': train_encodings['input_ids'],\n",
        "    'attention_mask': train_encodings['attention_mask'],\n",
        "    'labels': train_labels\n",
        "})\n",
        "\n",
        "val_dataset = Dataset.from_dict({\n",
        "    'input_ids': val_encodings['input_ids'],\n",
        "    'attention_mask': val_encodings['attention_mask'],\n",
        "    'labels': val_labels\n",
        "})\n",
        "\n",
        "test_dataset = Dataset.from_dict({\n",
        "    'input_ids': test_encodings['input_ids'],\n",
        "    'attention_mask': test_encodings['attention_mask'],\n",
        "    'labels': test_labels\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdTqlPabGUvd"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "# Classificação binária (polaridade)\n",
        "model = BertForSequenceClassification.from_pretrained('neuralmind/bert-base-portuguese-cased', num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    return {\"f1\": f1_score(p.label_ids, preds, average=\"macro\")}"
      ],
      "metadata": {
        "id": "7XkozTkBrtpN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FWdgczVyGYjl"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=4.840981590642851e-05, #Anterior: 2e-5\n",
        "    per_device_train_batch_size=8, #Anterior: 16\n",
        "    per_device_eval_batch_size=64, #Anterior: 64\n",
        "    num_train_epochs=2, #Anterior: 2\n",
        "    weight_decay=0.2755551526558927, #Anterior: 0.01\n",
        "    gradient_accumulation_steps=1, #Anterior: 2\n",
        "    warmup_ratio=0.04642400936685703, #Parâmetro não utilizado antes\n",
        "    metric_for_best_model=\"f1\", #Parâmetro não utilizado antes\n",
        "    fp16=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Tq2PRH5tGlet"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NyqWdDp_Gnm9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "9bcaae2a-d341-466d-8e5d-236b122b5c12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcleandersilva\u001b[0m (\u001b[33mcleandersilva-portal-puc-campinas\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250608_001057-joanr1dg</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/joanr1dg' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/joanr1dg' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/joanr1dg</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6664' max='6664' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6664/6664 13:40, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.231300</td>\n",
              "      <td>0.199261</td>\n",
              "      <td>0.915399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.162600</td>\n",
              "      <td>0.213406</td>\n",
              "      <td>0.931810</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=6664, training_loss=0.2114469962102883, metrics={'train_runtime': 852.6658, 'train_samples_per_second': 62.524, 'train_steps_per_second': 7.815, 'total_flos': 3506744145838080.0, 'train_loss': 0.2114469962102883, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Avaliando e Salvando o Modelo"
      ],
      "metadata": {
        "id": "3cWHe3qg4H8z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qzPTcBSYG0JN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "47d99735-6fa1-43d2-ef05-66c717ef39ba"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.20289386808872223,\n",
              " 'eval_f1': 0.9335099590097733,\n",
              " 'eval_runtime': 6.0944,\n",
              " 'eval_samples_per_second': 624.837,\n",
              " 'eval_steps_per_second': 9.845,\n",
              " 'epoch': 2.0}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "trainer.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import torch\n",
        "\n",
        "def compute_metrics(dataset):\n",
        "    predictions = trainer.predict(dataset)\n",
        "    preds = torch.argmax(torch.tensor(predictions.predictions), axis=1)\n",
        "    labels = dataset[\"labels\"]\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    report = classification_report(labels, preds, target_names=[\"Negativo\", \"Positivo\"])\n",
        "\n",
        "    print(f\"Acurácia: {accuracy:.4f}\")\n",
        "    print(\"Relatório de Classificação:\\n\", report)\n",
        "\n",
        "compute_metrics(test_dataset)"
      ],
      "metadata": {
        "id": "lIgi_pRhsHpc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "02896dd5-7be5-40d1-fe8f-2d4cda3e817f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 0.9435\n",
            "Relatório de Classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negativo       0.89      0.93      0.91      1140\n",
            "    Positivo       0.97      0.95      0.96      2668\n",
            "\n",
            "    accuracy                           0.94      3808\n",
            "   macro avg       0.93      0.94      0.93      3808\n",
            "weighted avg       0.94      0.94      0.94      3808\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model.save_pretrained(\"/content/drive/MyDrive/sentiment_model_optuna_tuned_v1.1\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/sentiment_model_optuna_tuned_v1.1\")"
      ],
      "metadata": {
        "id": "Id2lDMC5ZLKC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cc1e364-c835-41c6-c406-015f1f78b1c9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/sentiment_model_optuna_tuned_v1.1/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/sentiment_model_optuna_tuned_v1.1/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/sentiment_model_optuna_tuned_v1.1/vocab.txt',\n",
              " '/content/drive/MyDrive/sentiment_model_optuna_tuned_v1.1/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/sentiment_model_optuna_tuned_v1.1\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"/content/drive/MyDrive/sentiment_model_optuna_tuned_v1.1\")\n",
        "\n",
        "def predict_sentiment(texts):\n",
        "    encodings = tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "    outputs = model(**encodings)\n",
        "    predictions = outputs.logits.argmax(dim=-1)\n",
        "    return predictions\n",
        "\n",
        "textos = [\"Este úlitmo lançamento não foi legal\", \"Não podia ter comprado um produto melhor.\"]\n",
        "predictions = predict_sentiment(textos)\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "0DZ5OoTir_5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c533ab90-3a7b-4677-d7b4-334073cf3c27"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Avaliando modelo antigo"
      ],
      "metadata": {
        "id": "japmhod08yoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/sentiment_model\"\n",
        "\n",
        "old_model = BertForSequenceClassification.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "Sp5AeeRk82s6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "old_trainer = Trainer(\n",
        "    model=old_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset\n",
        ")"
      ],
      "metadata": {
        "id": "cPBKXvXl9MHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import torch\n",
        "\n",
        "def compute_old_model_metrics(dataset):\n",
        "    predictions = old_trainer.predict(dataset)\n",
        "    preds = torch.argmax(torch.tensor(predictions.predictions), axis=1)\n",
        "    labels = dataset[\"labels\"]\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    report = classification_report(labels, preds, target_names=[\"Negativo\", \"Positivo\"])\n",
        "\n",
        "    print(f\"Acurácia: {accuracy:.4f}\")\n",
        "    print(\"Relatório de Classificação:\\n\", report)\n",
        "\n",
        "compute_old_model_metrics(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "6NkutcbR9Pzj",
        "outputId": "595fe9c9-87a3-4e01-e841-a67969fd3e8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 0.9472\n",
            "Relatório de Classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negativo       0.90      0.93      0.91      1140\n",
            "    Positivo       0.97      0.95      0.96      2668\n",
            "\n",
            "    accuracy                           0.95      3808\n",
            "   macro avg       0.93      0.94      0.94      3808\n",
            "weighted avg       0.95      0.95      0.95      3808\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fazendo Fine-tuning dos Hiperparâmetros"
      ],
      "metadata": {
        "id": "d1PuE51VQsgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna"
      ],
      "metadata": {
        "id": "X3amlhYpROYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "import optuna\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    return {\"f1\": f1_score(p.label_ids, preds, average=\"macro\")}\n",
        "\n",
        "def model_init():\n",
        "    return BertForSequenceClassification.from_pretrained(\n",
        "        'neuralmind/bert-base-portuguese-cased',\n",
        "        num_labels=2\n",
        "    )\n",
        "\n",
        "def hp_space(trial):\n",
        "    return {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 5e-6, 5e-5, log=True),\n",
        "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16]),\n",
        "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 2, 5),\n",
        "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.3),\n",
        "        \"gradient_accumulation_steps\": trial.suggest_categorical(\"gradient_accumulation_steps\", [1, 2, 3, 4]),\n",
        "        \"warmup_ratio\": trial.suggest_float(\"warmup_ratio\", 0.0, 0.3),\n",
        "    }\n",
        "\n",
        "optuna_args = TrainingArguments(\n",
        "    output_dir=\"./optuna_test\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    per_device_eval_batch_size=64,\n",
        "    fp16=True,\n",
        "    save_total_limit=1,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\"\n",
        ")\n",
        "\n",
        "optuna_trainer = Trainer(\n",
        "    model_init=model_init,\n",
        "    args=optuna_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "print(\"Iniciando busca de hiperparâmetros com Optuna...\")\n",
        "\n",
        "best_run = optuna_trainer.hyperparameter_search(\n",
        "    direction=\"maximize\",\n",
        "    n_trials=15,\n",
        "    hp_space=hp_space,\n",
        "    backend=\"optuna\"\n",
        ")\n",
        "\n",
        "print(\"\\nMelhores hiperparâmetros encontrados:\")\n",
        "for param, value in best_run.hyperparameters.items():\n",
        "    print(f\"{param}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rDwUJ3OjQzXI",
        "outputId": "3ac4bcf3-bcfa-44d0-d5ad-7153350986a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-06-07 20:41:18,459] A new study created in memory with name: no-name-217af405-039f-40e1-80a2-dc33a658bf96\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando busca de hiperparâmetros com Optuna...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcleandersilva\u001b[0m (\u001b[33mcleandersilva-portal-puc-campinas\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250607_204153-6kwj2frx</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/6kwj2frx' target=\"_blank\">electric-dawn-14</a></strong> to <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/6kwj2frx' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/6kwj2frx</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3332' max='3332' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3332/3332 18:21, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.270400</td>\n",
              "      <td>0.177550</td>\n",
              "      <td>0.920306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.160300</td>\n",
              "      <td>0.166818</td>\n",
              "      <td>0.929976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.147600</td>\n",
              "      <td>0.176048</td>\n",
              "      <td>0.932205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.130200</td>\n",
              "      <td>0.180885</td>\n",
              "      <td>0.932501</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-07 21:00:19,249] Trial 0 finished with value: 0.9325009789725797 and parameters: {'learning_rate': 6.229243288212518e-06, 'per_device_train_batch_size': 8, 'num_train_epochs': 4, 'weight_decay': 0.1701338063494077, 'gradient_accumulation_steps': 4, 'warmup_ratio': 0.010867739418388034}. Best is trial 0 with value: 0.9325009789725797.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>▁▇██</td></tr><tr><td>eval/loss</td><td>▆▁▆█</td></tr><tr><td>eval/runtime</td><td>▁▄▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▅█▁</td></tr><tr><td>eval/steps_per_second</td><td>█▅█▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▄▅▆▆▇██</td></tr><tr><td>train/global_step</td><td>▁▂▂▃▄▅▆▆▇██</td></tr><tr><td>train/grad_norm</td><td>▆█▁▅▁▇</td></tr><tr><td>train/learning_rate</td><td>█▇▅▄▂▁</td></tr><tr><td>train/loss</td><td>█▄▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>0.9325</td></tr><tr><td>eval/loss</td><td>0.18089</td></tr><tr><td>eval/runtime</td><td>6.9617</td></tr><tr><td>eval/samples_per_second</td><td>546.99</td></tr><tr><td>eval/steps_per_second</td><td>8.619</td></tr><tr><td>total_flos</td><td>7013488291676160.0</td></tr><tr><td>train/epoch</td><td>4</td></tr><tr><td>train/global_step</td><td>3332</td></tr><tr><td>train/grad_norm</td><td>4.93066</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1302</td></tr><tr><td>train_loss</td><td>0.16856</td></tr><tr><td>train_runtime</td><td>1136.4808</td></tr><tr><td>train_samples_per_second</td><td>93.819</td></tr><tr><td>train_steps_per_second</td><td>2.932</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">electric-dawn-14</strong> at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/6kwj2frx' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/6kwj2frx</a><br> View project at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250607_204153-6kwj2frx/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250607_210022-5grc7rs8</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/5grc7rs8' target=\"_blank\">giddy-wildflower-15</a></strong> to <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/5grc7rs8' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/5grc7rs8</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9996' max='9996' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9996/9996 18:46, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.232200</td>\n",
              "      <td>0.229666</td>\n",
              "      <td>0.902494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.179900</td>\n",
              "      <td>0.183633</td>\n",
              "      <td>0.934565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.115400</td>\n",
              "      <td>0.235460</td>\n",
              "      <td>0.932991</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-07 21:19:11,225] Trial 1 finished with value: 0.9329905171571024 and parameters: {'learning_rate': 4.793943064208717e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 3, 'weight_decay': 0.024996744871575903, 'gradient_accumulation_steps': 1, 'warmup_ratio': 0.030215476310005106}. Best is trial 1 with value: 0.9329905171571024.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>▁██</td></tr><tr><td>eval/loss</td><td>▇▁█</td></tr><tr><td>eval/runtime</td><td>▁█▅</td></tr><tr><td>eval/samples_per_second</td><td>█▁▄</td></tr><tr><td>eval/steps_per_second</td><td>█▁▄</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▁▂▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁█▁</td></tr><tr><td>train/learning_rate</td><td>██▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▅▄▅▅▅▄▄▃▃▃▃▃▂▂▂▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>0.93299</td></tr><tr><td>eval/loss</td><td>0.23546</td></tr><tr><td>eval/runtime</td><td>6.88</td></tr><tr><td>eval/samples_per_second</td><td>553.489</td></tr><tr><td>eval/steps_per_second</td><td>8.721</td></tr><tr><td>total_flos</td><td>5260116218757120.0</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>9996</td></tr><tr><td>train/grad_norm</td><td>0.05339</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1154</td></tr><tr><td>train_loss</td><td>0.18948</td></tr><tr><td>train_runtime</td><td>1128.9394</td></tr><tr><td>train_samples_per_second</td><td>70.835</td></tr><tr><td>train_steps_per_second</td><td>8.854</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">giddy-wildflower-15</strong> at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/5grc7rs8' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/5grc7rs8</a><br> View project at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250607_210022-5grc7rs8/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250607_211914-9pnyl0sx</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/9pnyl0sx' target=\"_blank\">classic-cherry-16</a></strong> to <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/9pnyl0sx' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/9pnyl0sx</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6664' max='6664' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6664/6664 12:24, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.216800</td>\n",
              "      <td>0.191266</td>\n",
              "      <td>0.924728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.151100</td>\n",
              "      <td>0.204708</td>\n",
              "      <td>0.934924</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-07 21:31:40,659] Trial 2 finished with value: 0.9349236272175826 and parameters: {'learning_rate': 4.840981590642851e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 2, 'weight_decay': 0.2755551526558927, 'gradient_accumulation_steps': 1, 'warmup_ratio': 0.04642400936685703}. Best is trial 2 with value: 0.9349236272175826.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>▁█</td></tr><tr><td>eval/loss</td><td>▁█</td></tr><tr><td>eval/runtime</td><td>█▁</td></tr><tr><td>eval/samples_per_second</td><td>▁█</td></tr><tr><td>eval/steps_per_second</td><td>▁█</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▃▄▄▄▅▆▆▇▇███</td></tr><tr><td>train/global_step</td><td>▁▂▂▃▃▄▄▄▅▆▆▇▇███</td></tr><tr><td>train/grad_norm</td><td>▁▁▁▁▃▂▂█▁▁▂▁▁</td></tr><tr><td>train/learning_rate</td><td>█▇▇▆▆▅▅▄▃▃▂▂▁</td></tr><tr><td>train/loss</td><td>█▅▄▄▄▃▃▂▂▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>0.93492</td></tr><tr><td>eval/loss</td><td>0.20471</td></tr><tr><td>eval/runtime</td><td>6.9062</td></tr><tr><td>eval/samples_per_second</td><td>551.39</td></tr><tr><td>eval/steps_per_second</td><td>8.688</td></tr><tr><td>total_flos</td><td>3506744145838080.0</td></tr><tr><td>train/epoch</td><td>2</td></tr><tr><td>train/global_step</td><td>6664</td></tr><tr><td>train/grad_norm</td><td>0.33203</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1511</td></tr><tr><td>train_loss</td><td>0.20778</td></tr><tr><td>train_runtime</td><td>746.3923</td></tr><tr><td>train_samples_per_second</td><td>71.426</td></tr><tr><td>train_steps_per_second</td><td>8.928</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">classic-cherry-16</strong> at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/9pnyl0sx' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/9pnyl0sx</a><br> View project at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250607_211914-9pnyl0sx/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250607_213143-1e2oowp6</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/1e2oowp6' target=\"_blank\">balmy-pyramid-17</a></strong> to <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/1e2oowp6' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/1e2oowp6</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4165' max='4165' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4165/4165 20:48, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.392300</td>\n",
              "      <td>0.183951</td>\n",
              "      <td>0.920418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.166900</td>\n",
              "      <td>0.162985</td>\n",
              "      <td>0.931356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.153700</td>\n",
              "      <td>0.172530</td>\n",
              "      <td>0.929249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.126600</td>\n",
              "      <td>0.177117</td>\n",
              "      <td>0.930995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.116300</td>\n",
              "      <td>0.189477</td>\n",
              "      <td>0.929354</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-07 21:52:34,686] Trial 3 finished with value: 0.9293537615197454 and parameters: {'learning_rate': 6.900536899259329e-06, 'per_device_train_batch_size': 16, 'num_train_epochs': 5, 'weight_decay': 0.19715091674742594, 'gradient_accumulation_steps': 2, 'warmup_ratio': 0.16703785909835495}. Best is trial 2 with value: 0.9349236272175826.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>▁█▇█▇</td></tr><tr><td>eval/loss</td><td>▇▁▄▅█</td></tr><tr><td>eval/runtime</td><td>▁█▄▅▄</td></tr><tr><td>eval/samples_per_second</td><td>█▁▅▄▅</td></tr><tr><td>eval/steps_per_second</td><td>█▁▅▄▅</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▃▄▅▅▆▆▇███</td></tr><tr><td>train/global_step</td><td>▁▂▂▃▃▄▅▅▆▆▇███</td></tr><tr><td>train/grad_norm</td><td>▅▄▄▄▁▄▇█</td></tr><tr><td>train/learning_rate</td><td>▆█▇▆▄▃▂▁</td></tr><tr><td>train/loss</td><td>█▃▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>0.92935</td></tr><tr><td>eval/loss</td><td>0.18948</td></tr><tr><td>eval/runtime</td><td>6.9018</td></tr><tr><td>eval/samples_per_second</td><td>551.743</td></tr><tr><td>eval/steps_per_second</td><td>8.693</td></tr><tr><td>total_flos</td><td>8766860364595200.0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>4165</td></tr><tr><td>train/grad_norm</td><td>7.7672</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1163</td></tr><tr><td>train_loss</td><td>0.1753</td></tr><tr><td>train_runtime</td><td>1250.7588</td></tr><tr><td>train_samples_per_second</td><td>106.559</td></tr><tr><td>train_steps_per_second</td><td>3.33</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">balmy-pyramid-17</strong> at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/1e2oowp6' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/1e2oowp6</a><br> View project at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250607_213143-1e2oowp6/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250607_215237-7pcatxci</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/7pcatxci' target=\"_blank\">smooth-armadillo-18</a></strong> to <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/7pcatxci' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/7pcatxci</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='127' max='834' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [127/834 00:51 < 04:52, 2.42 it/s, Epoch 0.30/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='834' max='834' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [834/834 07:22, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.184819</td>\n",
              "      <td>0.925718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.266100</td>\n",
              "      <td>0.178954</td>\n",
              "      <td>0.927360</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-07 22:00:03,060] Trial 4 finished with value: 0.9273597154391857 and parameters: {'learning_rate': 5.5608315124188e-06, 'per_device_train_batch_size': 16, 'num_train_epochs': 2, 'weight_decay': 0.25858127676884646, 'gradient_accumulation_steps': 4, 'warmup_ratio': 0.06527188568547647}. Best is trial 2 with value: 0.9349236272175826.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>▁█</td></tr><tr><td>eval/loss</td><td>█▁</td></tr><tr><td>eval/runtime</td><td>█▁</td></tr><tr><td>eval/samples_per_second</td><td>▁█</td></tr><tr><td>eval/steps_per_second</td><td>▁█</td></tr><tr><td>train/epoch</td><td>▁▂██</td></tr><tr><td>train/global_step</td><td>▁▂██</td></tr><tr><td>train/grad_norm</td><td>▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>0.92736</td></tr><tr><td>eval/loss</td><td>0.17895</td></tr><tr><td>eval/runtime</td><td>6.8492</td></tr><tr><td>eval/samples_per_second</td><td>555.979</td></tr><tr><td>eval/steps_per_second</td><td>8.76</td></tr><tr><td>total_flos</td><td>3506744145838080.0</td></tr><tr><td>train/epoch</td><td>2</td></tr><tr><td>train/global_step</td><td>834</td></tr><tr><td>train/grad_norm</td><td>2.7468</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.2661</td></tr><tr><td>train_loss</td><td>0.22909</td></tr><tr><td>train_runtime</td><td>445.828</td></tr><tr><td>train_samples_per_second</td><td>119.58</td></tr><tr><td>train_steps_per_second</td><td>1.871</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">smooth-armadillo-18</strong> at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/7pcatxci' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/7pcatxci</a><br> View project at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250607_215237-7pcatxci/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250607_220005-5fxgj7rl</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/5fxgj7rl' target=\"_blank\">stoic-hill-19</a></strong> to <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/5fxgj7rl' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/5fxgj7rl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1666' max='6664' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1666/6664 03:48 < 11:25, 7.29 it/s, Epoch 1/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.207000</td>\n",
              "      <td>0.197827</td>\n",
              "      <td>0.904213</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-07 22:03:59,779] Trial 5 pruned. \n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▄▇█</td></tr><tr><td>train/global_step</td><td>▁▄▇█</td></tr><tr><td>train/grad_norm</td><td>█▁▃</td></tr><tr><td>train/learning_rate</td><td>▁▇█</td></tr><tr><td>train/loss</td><td>█▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>0.90421</td></tr><tr><td>eval/loss</td><td>0.19783</td></tr><tr><td>eval/runtime</td><td>6.9627</td></tr><tr><td>eval/samples_per_second</td><td>546.917</td></tr><tr><td>eval/steps_per_second</td><td>8.617</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>1666</td></tr><tr><td>train/grad_norm</td><td>5.48393</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/loss</td><td>0.207</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">stoic-hill-19</strong> at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/5fxgj7rl' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/5fxgj7rl</a><br> View project at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250607_220005-5fxgj7rl/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250607_220402-n8vme7lq</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/n8vme7lq' target=\"_blank\">prime-blaze-20</a></strong> to <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/n8vme7lq' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/n8vme7lq</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1666' max='6664' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1666/6664 03:48 < 11:26, 7.29 it/s, Epoch 1/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.204700</td>\n",
              "      <td>0.198043</td>\n",
              "      <td>0.923112</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-07 22:07:56,620] Trial 6 pruned. \n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▄▇█</td></tr><tr><td>train/global_step</td><td>▁▄▇█</td></tr><tr><td>train/grad_norm</td><td>▆▁█</td></tr><tr><td>train/learning_rate</td><td>▁█▇</td></tr><tr><td>train/loss</td><td>█▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>0.92311</td></tr><tr><td>eval/loss</td><td>0.19804</td></tr><tr><td>eval/runtime</td><td>6.8903</td></tr><tr><td>eval/samples_per_second</td><td>552.661</td></tr><tr><td>eval/steps_per_second</td><td>8.708</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>1666</td></tr><tr><td>train/grad_norm</td><td>5.98166</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.2047</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">prime-blaze-20</strong> at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/n8vme7lq' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/n8vme7lq</a><br> View project at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250607_220402-n8vme7lq/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250607_220759-g29e9y6e</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/g29e9y6e' target=\"_blank\">exalted-frog-21</a></strong> to <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/g29e9y6e' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/g29e9y6e</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1112' max='1112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1112/1112 07:00, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.263600</td>\n",
              "      <td>0.166989</td>\n",
              "      <td>0.928225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.155500</td>\n",
              "      <td>0.164098</td>\n",
              "      <td>0.930339</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-07 22:15:06,765] Trial 7 finished with value: 0.9303387707168559 and parameters: {'learning_rate': 1.1478196809318994e-05, 'per_device_train_batch_size': 16, 'num_train_epochs': 2, 'weight_decay': 0.20422806059467968, 'gradient_accumulation_steps': 3, 'warmup_ratio': 0.12061593785961211}. Best is trial 2 with value: 0.9349236272175826.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>▁█</td></tr><tr><td>eval/loss</td><td>█▁</td></tr><tr><td>eval/runtime</td><td>▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▁</td></tr><tr><td>eval/steps_per_second</td><td>█▁</td></tr><tr><td>train/epoch</td><td>▁▂▇██</td></tr><tr><td>train/global_step</td><td>▁▂▇██</td></tr><tr><td>train/grad_norm</td><td>▁█</td></tr><tr><td>train/learning_rate</td><td>█▁</td></tr><tr><td>train/loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>0.93034</td></tr><tr><td>eval/loss</td><td>0.1641</td></tr><tr><td>eval/runtime</td><td>6.9265</td></tr><tr><td>eval/samples_per_second</td><td>549.772</td></tr><tr><td>eval/steps_per_second</td><td>8.662</td></tr><tr><td>total_flos</td><td>3681449886597120.0</td></tr><tr><td>train/epoch</td><td>2</td></tr><tr><td>train/global_step</td><td>1112</td></tr><tr><td>train/grad_norm</td><td>2.7017</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1555</td></tr><tr><td>train_loss</td><td>0.20393</td></tr><tr><td>train_runtime</td><td>427.6563</td></tr><tr><td>train_samples_per_second</td><td>124.661</td></tr><tr><td>train_steps_per_second</td><td>2.6</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">exalted-frog-21</strong> at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/g29e9y6e' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/g29e9y6e</a><br> View project at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250607_220759-g29e9y6e/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250607_221509-rvy3beqp</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/rvy3beqp' target=\"_blank\">lilac-voice-22</a></strong> to <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/rvy3beqp' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/rvy3beqp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='556' max='2780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 556/2780 03:03 < 12:17, 3.01 it/s, Epoch 1/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.282300</td>\n",
              "      <td>0.194362</td>\n",
              "      <td>0.901953</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-07 22:18:19,173] Trial 8 pruned. \n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁█</td></tr><tr><td>train/global_step</td><td>▁█</td></tr><tr><td>train/grad_norm</td><td>▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>0.90195</td></tr><tr><td>eval/loss</td><td>0.19436</td></tr><tr><td>eval/runtime</td><td>6.8372</td></tr><tr><td>eval/samples_per_second</td><td>556.952</td></tr><tr><td>eval/steps_per_second</td><td>8.776</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>556</td></tr><tr><td>train/grad_norm</td><td>3.01455</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.2823</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lilac-voice-22</strong> at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/rvy3beqp' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/rvy3beqp</a><br> View project at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250607_221509-rvy3beqp/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250607_221822-fdl7pk68</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/fdl7pk68' target=\"_blank\">trim-field-23</a></strong> to <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/fdl7pk68' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/fdl7pk68</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2222' max='2222' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2222/2222 08:25, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.175195</td>\n",
              "      <td>0.927787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.139200</td>\n",
              "      <td>0.174142</td>\n",
              "      <td>0.931062</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-07 22:26:55,095] Trial 9 finished with value: 0.931062017567208 and parameters: {'learning_rate': 2.395791502451541e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 2, 'weight_decay': 0.012804252680517858, 'gradient_accumulation_steps': 3, 'warmup_ratio': 0.14925682238816249}. Best is trial 2 with value: 0.9349236272175826.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>▁█</td></tr><tr><td>eval/loss</td><td>█▁</td></tr><tr><td>eval/runtime</td><td>█▁</td></tr><tr><td>eval/samples_per_second</td><td>▁█</td></tr><tr><td>eval/steps_per_second</td><td>▁█</td></tr><tr><td>train/epoch</td><td>▁▃▃▅▇██</td></tr><tr><td>train/global_step</td><td>▁▃▃▅▇██</td></tr><tr><td>train/grad_norm</td><td>█▂▂▁</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>0.93106</td></tr><tr><td>eval/loss</td><td>0.17414</td></tr><tr><td>eval/runtime</td><td>6.8777</td></tr><tr><td>eval/samples_per_second</td><td>553.672</td></tr><tr><td>eval/steps_per_second</td><td>8.724</td></tr><tr><td>total_flos</td><td>3681449886597120.0</td></tr><tr><td>train/epoch</td><td>2</td></tr><tr><td>train/global_step</td><td>2222</td></tr><tr><td>train/grad_norm</td><td>0.5978</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1392</td></tr><tr><td>train_loss</td><td>0.18801</td></tr><tr><td>train_runtime</td><td>512.6962</td></tr><tr><td>train_samples_per_second</td><td>103.984</td></tr><tr><td>train_steps_per_second</td><td>4.334</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trim-field-23</strong> at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/fdl7pk68' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/fdl7pk68</a><br> View project at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250607_221822-fdl7pk68/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250607_222657-r9iamkwz</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/r9iamkwz' target=\"_blank\">dauntless-haze-24</a></strong> to <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/r9iamkwz' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/r9iamkwz</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1666' max='4998' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1666/4998 04:22 < 08:45, 6.35 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.211600</td>\n",
              "      <td>0.228071</td>\n",
              "      <td>0.890534</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-07 22:31:25,808] Trial 10 pruned. \n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▄▇█</td></tr><tr><td>train/global_step</td><td>▁▄▇█</td></tr><tr><td>train/grad_norm</td><td>█▁▅</td></tr><tr><td>train/learning_rate</td><td>▁▅█</td></tr><tr><td>train/loss</td><td>█▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>0.89053</td></tr><tr><td>eval/loss</td><td>0.22807</td></tr><tr><td>eval/runtime</td><td>6.9458</td></tr><tr><td>eval/samples_per_second</td><td>548.242</td></tr><tr><td>eval/steps_per_second</td><td>8.638</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>1666</td></tr><tr><td>train/grad_norm</td><td>2.06268</td></tr><tr><td>train/learning_rate</td><td>5e-05</td></tr><tr><td>train/loss</td><td>0.2116</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dauntless-haze-24</strong> at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/r9iamkwz' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/r9iamkwz</a><br> View project at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250607_222657-r9iamkwz/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250607_223128-kqwvcdeg</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/kqwvcdeg' target=\"_blank\">woven-wildflower-25</a></strong> to <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/kqwvcdeg' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/kqwvcdeg</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3332' max='9996' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3332/9996 05:31 < 11:04, 10.03 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.225500</td>\n",
              "      <td>0.195136</td>\n",
              "      <td>0.917887</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-07 22:37:06,123] Trial 11 pruned. \n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▂▃▅▆▇█</td></tr><tr><td>train/global_step</td><td>▁▂▃▅▆▇█</td></tr><tr><td>train/grad_norm</td><td>▂█▁▁▂▇</td></tr><tr><td>train/learning_rate</td><td>█▇▅▄▂▁</td></tr><tr><td>train/loss</td><td>█▃▂▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>0.91789</td></tr><tr><td>eval/loss</td><td>0.19514</td></tr><tr><td>eval/runtime</td><td>6.8171</td></tr><tr><td>eval/samples_per_second</td><td>558.599</td></tr><tr><td>eval/steps_per_second</td><td>8.801</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>3332</td></tr><tr><td>train/grad_norm</td><td>7.75621</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/loss</td><td>0.2255</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">woven-wildflower-25</strong> at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/kqwvcdeg' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/kqwvcdeg</a><br> View project at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250607_223128-kqwvcdeg/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250607_223708-18pw58ln</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/18pw58ln' target=\"_blank\">eternal-haze-26</a></strong> to <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/18pw58ln' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/18pw58ln</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3332' max='9996' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3332/9996 05:29 < 10:59, 10.10 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.218600</td>\n",
              "      <td>0.213955</td>\n",
              "      <td>0.920821</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-07 22:42:44,199] Trial 12 pruned. \n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▂▃▅▆▇█</td></tr><tr><td>train/global_step</td><td>▁▂▃▅▆▇█</td></tr><tr><td>train/grad_norm</td><td>▂▁▁▁▁█</td></tr><tr><td>train/learning_rate</td><td>▃█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▄▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>0.92082</td></tr><tr><td>eval/loss</td><td>0.21395</td></tr><tr><td>eval/runtime</td><td>6.9521</td></tr><tr><td>eval/samples_per_second</td><td>547.75</td></tr><tr><td>eval/steps_per_second</td><td>8.631</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>3332</td></tr><tr><td>train/grad_norm</td><td>7.48538</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.2186</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">eternal-haze-26</strong> at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/18pw58ln' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/18pw58ln</a><br> View project at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250607_223708-18pw58ln/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250607_224246-cp7awoca</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/cp7awoca' target=\"_blank\">lilac-totem-27</a></strong> to <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/cp7awoca' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/cp7awoca</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3332' max='6664' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3332/6664 05:30 < 05:30, 10.08 it/s, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.210100</td>\n",
              "      <td>0.222612</td>\n",
              "      <td>0.915558</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-07 22:48:23,135] Trial 13 pruned. \n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▂▃▅▆▇█</td></tr><tr><td>train/global_step</td><td>▁▂▃▅▆▇█</td></tr><tr><td>train/grad_norm</td><td>▃▁▁▁▆█</td></tr><tr><td>train/learning_rate</td><td>█▇▅▄▂▁</td></tr><tr><td>train/loss</td><td>█▃▂▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>0.91556</td></tr><tr><td>eval/loss</td><td>0.22261</td></tr><tr><td>eval/runtime</td><td>6.8651</td></tr><tr><td>eval/samples_per_second</td><td>554.691</td></tr><tr><td>eval/steps_per_second</td><td>8.74</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>3332</td></tr><tr><td>train/grad_norm</td><td>1.20404</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.2101</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lilac-totem-27</strong> at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/cp7awoca' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/cp7awoca</a><br> View project at: <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250607_224246-cp7awoca/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250607_224825-dyztk6ol</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/dyztk6ol' target=\"_blank\">ethereal-shadow-28</a></strong> to <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/dyztk6ol' target=\"_blank\">https://wandb.ai/cleandersilva-portal-puc-campinas/huggingface/runs/dyztk6ol</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3332' max='9996' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3332/9996 05:30 < 11:00, 10.09 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.229300</td>\n",
              "      <td>0.231783</td>\n",
              "      <td>0.916564</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-07 22:54:01,807] Trial 14 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Melhores hiperparâmetros encontrados:\n",
            "learning_rate: 4.840981590642851e-05\n",
            "per_device_train_batch_size: 8\n",
            "num_train_epochs: 2\n",
            "weight_decay: 0.2755551526558927\n",
            "gradient_accumulation_steps: 1\n",
            "warmup_ratio: 0.04642400936685703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Utilizando o Modelo e a API"
      ],
      "metadata": {
        "id": "Oi2LANNtHDhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fpdf"
      ],
      "metadata": {
        "id": "CUIGt1fR0CP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfba910b-f690-412b-cf01-fcd20d39eecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=25af2d0882f3a2815509c7ced48b376fba8956a16bd98c7deff7cc5ffe725443\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/66/bbda9866da446a72e206d6484cd97381cbc7859a7068541c36\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf\n",
            "Successfully installed fpdf-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "from fpdf import FPDF\n",
        "from datetime import datetime\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uOMeTGvEHG7o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3578584-453a-4fc8-f77e-26394b756e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ig_user_id = \"17841449666813574\"\n",
        "app_id = \"1750857045465243\"\n",
        "app_secret = \"3879b6aeb6718a852a5bed85f1ab5fde\"\n",
        "user_access_token = \"EAAY4ZASwZCWJsBO9DOETVck86K7likqssFJ88bX96jfn00zEr2QWY40D1kqpJ9BtfDtGMCwZBr2C1iYj7mVPTPSQjIZA5p3shN7WTPyyYB9xpBlCkvmz23uFrL6iTz15hUl0d7ZAGwcZA0jicA0j1yghUofENIClhf70xzMwlrbVvJb8b0SLyPg9fcUvK4Jwgw09kC2rplqc0Ds0H2mAZDZD\"\n",
        "\n",
        "url = f\"https://graph.facebook.com/v17.0/oauth/access_token?grant_type=fb_exchange_token&client_id={app_id}&client_secret={app_secret}&fb_exchange_token={user_access_token}\"\n",
        "response = requests.get(url)\n",
        "long_access_token = response.json()[\"access_token\"]\n",
        "\n",
        "base_url = f\"https://graph.facebook.com/v17.0/{ig_user_id}/media?fields=id,caption,timestamp&access_token={long_access_token}\"\n",
        "\n",
        "if not os.path.exists('graficos'):\n",
        "    os.makedirs('graficos')"
      ],
      "metadata": {
        "id": "EB4U_ShlIKa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def coletar_comentarios_por_publicacao():\n",
        "    publicacoes = []\n",
        "    response = requests.get(base_url)\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()['data']\n",
        "        for item in data:\n",
        "            media_id = item['id']\n",
        "            caption = item.get('caption', 'Sem legenda')\n",
        "            timestamp = item.get('timestamp', None)\n",
        "\n",
        "            comments_url = f'https://graph.facebook.com/v17.0/{media_id}/comments?fields=id,text,timestamp,username&access_token={long_access_token}'\n",
        "            comments_response = requests.get(comments_url)\n",
        "\n",
        "            comentarios = []\n",
        "            if comments_response.status_code == 200:\n",
        "                comments_data = comments_response.json().get('data', [])\n",
        "                comentarios = [comment['text'] for comment in comments_data]\n",
        "            else:\n",
        "                print(f'Erro ao buscar comentários da mídia {media_id}')\n",
        "\n",
        "            publicacoes.append({\n",
        "                'media_id': media_id,\n",
        "                'caption': caption,\n",
        "                'comentarios': comentarios,\n",
        "                'timestamp': timestamp\n",
        "            })\n",
        "    else:\n",
        "        print('Erro ao buscar mídias:', response.text)\n",
        "\n",
        "    return publicacoes"
      ],
      "metadata": {
        "id": "0WNEh0pEJIvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/sentiment_model\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"/content/drive/MyDrive/sentiment_model\")"
      ],
      "metadata": {
        "id": "zQbm1TV1Qrq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analisar_sentimentos(comentarios):\n",
        "    resultados = []\n",
        "    if comentarios:\n",
        "        encodings = tokenizer(comentarios, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**encodings)\n",
        "            predictions = outputs.logits.argmax(dim=-1)\n",
        "\n",
        "        for comentario, pred in zip(comentarios, predictions):\n",
        "            sentimento = 'Positivo' if pred.item() == 1 else 'Negativo'\n",
        "            resultados.append((comentario, sentimento))\n",
        "    return resultados"
      ],
      "metadata": {
        "id": "OesD4VvtQ7nY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calcular_metricas(resultados):\n",
        "    total = len(resultados)\n",
        "    positivos = sum(1 for _, s in resultados if s == 'Positivo')\n",
        "    negativos = total - positivos\n",
        "    porcentagem_positivos = positivos / total * 100 if total else 0\n",
        "    porcentagem_negativos = negativos / total * 100 if total else 0\n",
        "    return positivos, negativos, porcentagem_positivos, porcentagem_negativos"
      ],
      "metadata": {
        "id": "hhvnWPxuUOQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_grafico_publicacao(caption, positivos, negativos, media_id):\n",
        "    labels = ['Positivos', 'Negativos']\n",
        "    sizes = [positivos, negativos]\n",
        "    colors = ['#4CAF50', '#F44336']\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors)\n",
        "    ax.axis('equal')\n",
        "    plt.title(caption[:50] + '...')\n",
        "    caminho = f'graficos/{media_id}.png'\n",
        "    plt.savefig(caminho)\n",
        "    plt.close()\n",
        "    return caminho\n",
        "\n",
        "\"\"\"\n",
        "def gerar_grafico_geral(total_positivos, total_negativos):\n",
        "    labels = ['Positivos', 'Negativos']\n",
        "    sizes = [total_positivos, total_negativos]\n",
        "    colors = ['#4CAF50', '#F44336']\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors)\n",
        "    ax.axis('equal')\n",
        "    plt.title('Distribuição Geral dos Sentimentos')\n",
        "    caminho = 'graficos/geral.png'\n",
        "    plt.savefig(caminho)\n",
        "    plt.close()\n",
        "    return caminho\n",
        "\"\"\"\n",
        "\n",
        "def gerar_grafico_temporal(resultados_temporais):\n",
        "    if not resultados_temporais:\n",
        "        return None\n",
        "\n",
        "    resultados_ordenados = sorted(resultados_temporais, key=lambda x: x['data'])\n",
        "\n",
        "    datas = [\n",
        "      datetime.strptime(item['data'], '%Y-%m-%dT%H:%M:%S%z').strftime('%d/%m/%Y %H:%M')\n",
        "      for item in resultados_ordenados\n",
        "    ]\n",
        "\n",
        "    porcentagens = [item['pct_positivos'] for item in resultados_ordenados]\n",
        "    legends = [item['caption'][:30] + '...' if len(item['caption']) > 30 else item['caption'] for item in resultados_ordenados]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    ax.plot(datas, porcentagens, marker='o', color='#2196F3', linestyle='-')\n",
        "\n",
        "    for i, txt in enumerate(legends):\n",
        "        ax.annotate(txt, (i, porcentagens[i]), textcoords=\"offset points\", xytext=(0,10),\n",
        "                    ha='center', fontsize=8, rotation=45)\n",
        "\n",
        "    ax.set_xticks(datas)\n",
        "    ax.set_xticklabels(datas, rotation=45, ha='right', fontsize=8)\n",
        "\n",
        "    ax.set_title('Evolução da Avaliação das Publicações ao Longo do Tempo')\n",
        "    ax.set_xlabel('Data da Publicação')\n",
        "    ax.set_ylabel('% de Comentários Positivos')\n",
        "    ax.set_ylim(0, 100)\n",
        "    ax.grid(True)\n",
        "\n",
        "    caminho = 'graficos/grafico_temporal.png'\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(caminho)\n",
        "    plt.close()\n",
        "    return caminho\n"
      ],
      "metadata": {
        "id": "cTDDtRQnUSiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Função utilizada na solução provisória para os emojis dando erro ao gerar o pdf\n",
        "def remove_emojis(text):\n",
        "    return text.encode('latin-1', 'ignore').decode('latin-1')"
      ],
      "metadata": {
        "id": "BKsIFrFaIWQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PDFRelatorio(FPDF):\n",
        "    def header(self):\n",
        "        self.set_font('Arial', 'B', 16)\n",
        "        self.cell(0, 10, 'Relatório de Análise de Sentimentos - Instagram', 0, 1, 'C')\n",
        "        self.ln(10)\n",
        "\n",
        "    def footer(self):\n",
        "        self.set_y(-15)\n",
        "        self.set_font('Arial', 'I', 8)\n",
        "        self.cell(0, 10, f'Página {self.page_no()}', 0, 0, 'C')\n",
        "\n",
        "    def add_publicacao(self, caption, positivos, negativos, porcentagem_positivos, porcentagem_negativos, grafico_path):\n",
        "        self.set_font('Arial', 'B', 12)\n",
        "        #Solução provisória para os emojis\n",
        "        self.multi_cell(0, 10, remove_emojis(caption))\n",
        "        self.set_font('Arial', '', 12)\n",
        "        self.cell(0, 10, f'Positivos: {positivos} ({porcentagem_positivos:.2f}%)', 0, 1)\n",
        "        self.cell(0, 10, f'Negativos: {negativos} ({porcentagem_negativos:.2f}%)', 0, 1)\n",
        "        self.ln(3)\n",
        "        self.image(grafico_path, w=150)\n",
        "        self.ln(10)\n",
        "\n",
        "    def add_conclusao_geral(self, total_positivos, total_negativos, pct_positivos, pct_negativos, grafico_path):\n",
        "        self.add_page()\n",
        "        self.set_font('Arial', 'B', 14)\n",
        "        self.cell(0, 10, 'Resumo Geral', 0, 1, 'C')\n",
        "        self.ln(5)\n",
        "        self.set_font('Arial', '', 12)\n",
        "        self.cell(0, 10, f'Total de Comentários Positivos: {total_positivos} ({pct_positivos:.2f}%)', 0, 1)\n",
        "        self.cell(0, 10, f'Total de Comentários Negativos: {total_negativos} ({pct_negativos:.2f}%)', 0, 1)\n",
        "        self.ln(5)\n",
        "        self.image(grafico_path, w=150)\n",
        "        self.ln(10)\n",
        "\n",
        "        conclusao = 'Conclusão geral: '\n",
        "        if pct_positivos > 70:\n",
        "            conclusao += 'O perfil está muito bem avaliado!'\n",
        "        elif pct_positivos > 40:\n",
        "            conclusao += 'O perfil está com avaliação mista.'\n",
        "        else:\n",
        "            conclusao += 'O perfil está sendo mal avaliado.'\n",
        "\n",
        "        self.multi_cell(0, 10, conclusao)"
      ],
      "metadata": {
        "id": "piZ9pp2xUYLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Gerando o Relatório"
      ],
      "metadata": {
        "id": "mfAjQx_E7akr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "publicacoes = coletar_comentarios_por_publicacao()\n",
        "pdf = PDFRelatorio()\n",
        "pdf.add_page()\n",
        "\n",
        "print(publicacoes)\n",
        "\n",
        "total_resultados = []\n",
        "resultados_temporais = []\n",
        "\n",
        "total_positivos = 0\n",
        "total_negativos = 0\n",
        "\n",
        "for publicacao in publicacoes:\n",
        "    comentarios = publicacao['comentarios']\n",
        "    caption = publicacao['caption']\n",
        "    media_id = publicacao['media_id']\n",
        "\n",
        "    if comentarios:\n",
        "        resultados = analisar_sentimentos(comentarios)\n",
        "        positivos, negativos, pct_positivos, pct_negativos = calcular_metricas(resultados)\n",
        "        grafico_path = gerar_grafico_publicacao(caption, positivos, negativos, media_id)\n",
        "\n",
        "        pdf.add_publicacao(caption, positivos, negativos, pct_positivos, pct_negativos, grafico_path)\n",
        "\n",
        "        total_positivos += positivos\n",
        "        total_negativos += negativos\n",
        "        total_resultados.extend(resultados)\n",
        "\n",
        "        resultados_temporais.append({\n",
        "            'data': publicacao['timestamp'],\n",
        "            'pct_positivos': pct_positivos,\n",
        "            'caption': caption\n",
        "        })\n",
        "\n",
        "grafico_temporal_path = gerar_grafico_temporal(resultados_temporais)\n",
        "pct_total_positivos = total_positivos / (total_positivos + total_negativos) * 100 if (total_positivos + total_negativos) else 0\n",
        "pct_total_negativos = 100 - pct_total_positivos\n",
        "\n",
        "pdf.add_conclusao_geral(total_positivos, total_negativos, pct_total_positivos, pct_total_negativos, grafico_temporal_path)\n",
        "\n",
        "pdf.output('relatorio_sentimentos_instagram.pdf')"
      ],
      "metadata": {
        "id": "v0G3wOG3Uc3R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "180c81d9-dbfa-4214-bf19-8b31c6c13d6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'media_id': '17982061616675940', 'caption': 'O que esse negócio de I.A tá ficando bom em foto é brincadeira 😳', 'comentarios': ['Que lindosss❤️❤️', '❤️❤️❤️', 'A IA nao colocou aliança na sua foto 😠', 'Amei!! ❤️❤️', 'ta roubando o emprego do vasco', 'Legal que na terceira foto a Le não tá de olho fechado mas a IA entendeu que tava hahahaha', 'A Porsche virou fusca kkkkkkkk', 'show de bola🙌❤️', 'parece o dj oreia', 'ficou parecido irmão 👏👏'], 'timestamp': '2025-03-31T15:00:00+0000'}, {'media_id': '18487181953049729', 'caption': 'Obrigado por essa vista maravilhosa!! 🥹', 'comentarios': ['Kkkkkkkkkkkkk', '😂😂😂😂😂', '👏👏👏muito  bom', 'O que importa é a companhia!!', '😂😂😂', 'Nuussssss......deu ate medo 😂😂'], 'timestamp': '2025-01-06T16:19:11+0000'}, {'media_id': '18044393930191067', 'caption': 'Eu e você, você e eu ♥️', 'comentarios': ['👏👏👏👏👏👏👏👏👏', '🔥🔥🔥🔥🔥🔥kkkkk', '👏👏👏👏👏🔥🔥🔥🔥', '💘💘💘💘', 'linducos', 'Lindos amooooo ❤️❤️❤️', 'Seus lindos ❤️❤️', 'Lindicos', 'Meu tudinho', 'Te amo muito lindeza❤️❤️❤️'], 'timestamp': '2025-01-03T22:00:00+0000'}, {'media_id': '17942893244936864', 'caption': 'Como é bom viajar! 😂😂😂', 'comentarios': ['Rindo de nervoso', 'KKKKKKKKKK'], 'timestamp': '2025-01-01T15:14:17+0000'}, {'media_id': '18078186811539973', 'caption': 'Mais alguém aí não aguenta mais?! 😅😩', 'comentarios': ['😂😂😂', 'nao tanka 1 ano de clt', 'Estou em SAN Martin de los Andes . Frio p/ cacete', 'Muito eu 😂😂', 'Afinal a viagem foi legal ou não?'], 'timestamp': '2024-12-31T15:00:00+0000'}, {'media_id': '17864298684295236', 'caption': 'Como é esperar seu voo na Sala Vip da @nomadglobalapp? Vem comigo que eu te mostro! 💛\\n\\nEu e a minha namorada decidimos passar alguns dias fora do país e aproveitamos para esperar nosso voo na Sala Vio da Nomad no aeroporto de Guarulhos, não podia ser diferente, né?!\\n\\nQuer poder ter acesso a tudo isso que eu te mostrei no vídeo? Crie a sua conta internacional Nomad hoje e utilize o cupom STOCCO para garantir até 20 dólares de cashback!* 🤩\\n\\nNão perde tempo, vem ser Nomad! 💛\\n\\n*A sala vip é liberada para clientes Nível 2 Nomad e você pode ganhar até 20 dólares de cashback ao realizar a sua primeira operação de câmbio em até 15 dias da abertura da conta.\\n\\npubli', 'comentarios': ['👏👏👏👏👏👏', 'uauuuu', 'uauuuu!', 'Experiência incrível!  Muito obrigada @nomadglobalapp por todo o carinho e conforto! 💛💛💛', 'Salinha sinistra 🔥', '👏👏👏 picaaaaaaa', 'nomad > binomo @eversonzoio', 'amassaria essa mesa inteira', 'muiiito boa! obrigado @nomadglobalapp', 'Top demais 👏', 'Top hein 👏👏😍😍 ..... pode ja me dar essa manteiga de cacau q ganhou pq sei q nao usa 😁😁😁😁', 'Chocolate pra dormir eh amais kkkkkkkk', 'que gostosuras 👏', 'que chique achei melhor que a do mastercard'], 'timestamp': '2024-12-30T22:15:11+0000'}, {'media_id': '17999663492706726', 'caption': 'una coronita porfavorzito', 'comentarios': ['Na  ária👏👏👏👏', 'lindao ❤️', '👏👏👏👏', '👏👏👏👏', 'tão bonitinho, nem parece o ber', 'chiqueeee', 'ta mal 👏👏', 'uau bidus', 'acesso vip🔥', 'Uauuuuu hermoso ❤️😍😂😂😂', 'Que menino mais lindo!!!❤️❤️', 'Kkkk', 'Aindaaaa 😛✌🏻', 'Que hombre!', 'vuelasita também tema amorsito kkkkkk', 'manager 🔥', '😍😍😍😍😍😍😍😍😍😍😍😍😍', 'Te amo gostosito👏❤️', 'Uau gatinho'], 'timestamp': '2024-12-29T22:21:19+0000'}, {'media_id': '18082561189564865', 'caption': 'é nosso jeitinho de viajar, tá errado? 🤪 #reelsinstagram #viagem #reels', 'comentarios': ['Muito  legau  o  passeio', 'Isso é muito a gente kkkkk @maatheusvilela_', 'KKKKKKKKKKKKKKKK', 'Tb sou assim', '😂😂😂😂😂', '👏👏👏👏👏', 'Kkkkk', 'Kkkkkkkkk adorei', 'Kkkkkkkkkkkkk jovens jovens', 'Amei nossa viagem!', 'Eu devo ser a mãe de vocês…..😂😂', 'Kkkkkkkkkkkkk'], 'timestamp': '2024-12-28T22:24:36+0000'}, {'media_id': '17858794836302414', 'caption': '06.12 ♥️ postando só as nossas melhores fotos', 'comentarios': ['muito bom ver o amor de vcs!❤️❤️', '😍😍😍', 'Kkkkkkkkkk Deus abençoe vocês!! Feliz 1 ano! Amo vcs ❤️❤️❤️', 'Na ARIA 👏👏👏', 'Meus amores ❤️❤️', 'Tudinho', 'Te amo tanto❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️', 'KKKKKKKKKKKK', 'Meu irmão bom dia Deus abençoe perdão pelo horário por gentileza eu posso tomar um minutinho da sua atenção'], 'timestamp': '2024-12-06T03:34:31+0000'}, {'media_id': '18321180199084064', 'caption': 'é sério levem eles!!!', 'comentarios': ['😂😂😂😂😂😂', 'KKKKKKKKKK ops'], 'timestamp': '2024-11-12T15:00:00+0000'}, {'media_id': '17910494946020255', 'caption': 'Achei perdido nos rascunhos! Tinha esquecido de postar essa nossa viagem para Brotas!! 😍❤️ #reels #reelsinstagram #viagem #casal #trip', 'comentarios': ['Ê  isso ai  na aria', 'lindossss ❤️', 'Q gays', '😍😍😍😍😍😍', 'Lindos ❤️❤️❤️❤️', '😍😍😍', 'Lindos ❤️❤️❤️❤️ amoooo', 'Lindos demais', 'Ahhh que lindos!!!!❤️'], 'timestamp': '2024-11-06T20:33:22+0000'}, {'media_id': '18072248605579629', 'caption': 'fim de semana em noronha, tá liberado?', 'comentarios': ['Fotao ber!!! ❤️❤️❤️', 'a loc tá errada, devia estar “localiza aí comédia” 🎭', 'vive bem e se diverte 👏👏', 'Te amo❤️', 'Que tumblr👏👏'], 'timestamp': '2024-10-06T16:16:52+0000'}, {'media_id': '18056109424766756', 'caption': 'Eu adorava quando isso acontecia KKKKKKKK', 'comentarios': ['😂😂😂😂😂😂😂😂😂', 'KKKKKKKKKKKKK', 'KKKKKKKKKKKKK', 'KKKKKKKKKKKKKKKKKK', 'IGUALL KAKAKKAKAKKAK', 'É assim mesmo 😂😂👏👏'], 'timestamp': '2024-09-14T15:00:00+0000'}, {'media_id': '18057739990689080', 'caption': 'Não era pra VOCÊ  tá dormindo não amigão! 🤦🏻\\u200d♂️', 'comentarios': ['i a música? descobriu o nome?', 'e o nome da música?', 'e o nome da música pae?', 'qual nome da música, meu patrão?', 'qual nome da música, meu campeão?', 'E so  freiar  que  acorda', '😂😂😂😂', 'qual nome da música, meu consagrado?', 'sair dps do almoço é foda', '😂😂😂', 'Pior que ja peguei uber com esse cara uma vez, toda vez isso, irresponsabilidade imensa!'], 'timestamp': '2024-09-13T15:00:00+0000'}, {'media_id': '17935237541793963', 'caption': 'Você pode não falar inglês, mas a Nomad fala por você.\\nAbra sua conta Nomad e viaje pelo mundo economizando com a cotação do câmbio comercial.\\nE aplicando o código de convidado STOCCO na abertura da conta, você ganha até 20 dólares de cashback na sua primeira operação de câmbio feita em até 15 dias da abertura da conta. É só clicar no link da BIO 😉\\n \\n - Aceito em mais de 180 países\\n- Atendimento 100% em português\\n- IOF de 1,1% muito mais barato do que cartão de crédito internacional - Cotação do câmbio comercial\\n- Segurança de não precisar levar dinheiro em espécie\\n- Cartão de débito internacional virtual e físico\\n\\n*publi*', 'comentarios': ['Vai  pra ARGENTINA', 'Hahaha me divirto com seis posts!!! Muito dez👏👏👏👏👏', '@leishikawavilela como assim vc tirou os cílios le????', '@leishikawavilela , vc cortou o cabelo? Tá meio diferente', 'Leticia ta tomando trembo', 'Muito bom!!! 😂😂😂', 'A Letícia 👩🏻😂😂😂😂', 'eu te amooooooo nomad', 'a leticia de camisa do brasil fica diferente ne', 'Bela publi', 'Mlk tu tá muito ator KKKKKKKKK', 'letícia tá diferente', 'A Nomad é mesmo incrível!! 😍😍😍'], 'timestamp': '2024-09-12T15:07:30+0000'}, {'media_id': '18054918988764426', 'caption': 'Manda para aquele amigo que passou aqui pra retirar o título 👀👀', 'comentarios': ['@pedro.eloii_', '@pedro.eloii_', '@pedro.eloii_'], 'timestamp': '2024-09-11T21:00:00+0000'}, {'media_id': '18132364018367165', 'caption': 'É SEMPRE assim kkkkkk', 'comentarios': ['Muito bom', 'As resenhas no Le carnê de peixê eram as melhores', 'batataixxxxxx', 'Kkkkkkk muito bom!👏', 'Ator e os krl', '🍸', 'saudades daquele 15 de setembro quando a gente saboreou aquela lagosta e aquele baião de dois no Témõs Lagostą Camarón', 'Vou te contratar .... rsrrs', 'Que isso gnt!??? Kkkkk', 'meu detetive preferido😮\\u200d💨😮\\u200d💨😮\\u200d💨', 'eu amo', 'é sempre assimmmmm kkkkkkkkkk', 'meu sonho e ir pra chupinguaia', 'Chupinguaia ta pocando em 😂👏', 'Peçanha é fod@ 😂', 'Igualzin AKAKKAKAAKAKAK'], 'timestamp': '2024-09-09T21:00:00+0000'}, {'media_id': '18032017490469795', 'caption': 'Eu não aguento mais essa vida do triguinho 😫😫 ib: @_eu_lucaxx', 'comentarios': ['Joga mais  20  contos', '😂😂😂', '😂😂😂', 'gera jogar mais 20', 'plataforma ta pagando muitoooo', 'mkkkkkkkkkkkkkkkkk', 'Só mais 20tin vai KAKAKAK', 'capeta com essa cara'], 'timestamp': '2024-09-07T15:00:00+0000'}, {'media_id': '17842787517309690', 'caption': 'Pov: eu sou o vizinho 😅', 'comentarios': ['KAKAKAKKAKA', 'kkkkkkkkkkkkkk sempre assim', 'todo dia isso'], 'timestamp': '2024-09-05T15:39:58+0000'}, {'media_id': '18460250785028287', 'caption': 'Eu admito, sou viciado em mentir 🙋🏻\\u200d♂️', 'comentarios': ['😂😂😂😂😂', 'Kkkkk adorei as mentiras😂😂😂😂', 'A Demi HAHAHAHAHAHAHAHAHA', 'parabens', 'KKKKKKKKK pior q eu ri desse', '😂😂', 'Guerra em Goiás foi foda kkkkkkkk', 'demi lovato kkkkkkkkkkkkkkkk', '😂😂', 'ta foda, Demi', '😂😂😂', 'KKKKKKKKKKKKKKKKKK', '📍Chupinguaia - RO', 'pior que a historia verdadeira da placa é triste', 'KAKAKAKAKAKAK', 'Que isso demo lovato, em chupinguaia é osso 😂😂😂'], 'timestamp': '2024-09-04T15:00:00+0000'}, {'media_id': '18024718721110765', 'caption': 'Todo mundo conhece alguém assim KKKKKKKKKK', 'comentarios': ['Reclama pro xandao 😂', '😢', '😮😮', 'KKKKKKKKKKKKKK', 'mds', 'KKKKKKKKKKKKKKKKKKKK SOS', '😂😂😂', '@gabipianca', '@justochh'], 'timestamp': '2024-08-31T20:29:42+0000'}, {'media_id': '18002749895419060', 'caption': 'Sabe aquela fome que bate de madrugada?! \\n\\nA BOLD é a barrinha perfeita para te salvar dessa situação terrível! É só esquentar ela por 15 a 20 segundos no microondas e tá pronta! Fica uma delícia!\\n\\nGaranta as suas barrinhas utilizando o cupom STOCCO na hora do pagamento ou clicando no link da minha bio! 😍 Experimenta por aí @boldsnacks\\n\\n*publi* #boldsnacks #boldsalva', 'comentarios': ['Isso não me slknents de madrugada não... aliás  geralmente nem como nada de madrugada', 'Altão e não viu essa linda barrinha emcima da geladeira, abre o olho malandro', 'fica bem suculenta quando coloca no microondas, amo!!', 'eu amoooo essa barrinha!!🤤🤤🤤', '@gabi2cordeiro assista isso 😮😮😮', 'que delícia! a barra tambem parece super boa.', 'A melhor q ja comi na vida 😋😋', 'Delícia!', 'Essa barrinha da Bold é muito boa!!!! Ja comprei a minha com desconto!!!', 'que fome de bold 😋'], 'timestamp': '2024-07-31T15:00:00+0000'}, {'media_id': '17928069383795956', 'caption': 'Quem aí também pegaria só a barrinha da BOLD?? 😅\\n\\nA BOLD é uma barrinha rica em proteína e muito sabor. Perfeita pra quem quer se alimentar de forma saudável, praticar exercícios ou só comer um snack gostoso mesmo!\\n\\nGaranta as suas barrinhas utilizando o cupom STOCCO na hora do pagamento ou clicando no link da minha bio! 😍 Experimenta por aí! 😋 @boldsnacks \\n\\n*publi* #boldsnacks #boldsalva', 'comentarios': ['bold é vida 🙌', 'ISSO  QUE  E GOSTAR  DR  CHOCOLAYE', 'O resto do presente manda aqui kkkk', 'fodaaaaa', 'Adorooooooo 👏👏👏👏', 'minha favorita!!! ❤️❤️❤️', 'amei o presente🥰🥰🥰', 'Kkkkkkk', 'Gosto da Brownie', 'opa percebi que seu perfil se qualifica para participar da', 'kkkkkk é disso que elas gostam', 'Gênio kkkkkkkk', 'Kkkkkkkkkkkkk', 'pior que a barra e legal mesmo!', '😂👏', 'Essa ai é a top 2 pra mim, so perde pra de', 'KKKKKKKKKKKKKKKKKKKKK eu amei!', 'diferenciado', 'Genio do mkt', 'Eu teria escolhido igual! 😋😋😋', 'Kkkkkkkkkkk muita humildade', 'Kkkkk essa barrinha é boa mesmo!!!!'], 'timestamp': '2024-07-27T15:00:00+0000'}, {'media_id': '18053683015687917', 'caption': \"McDonald's 1 Estrela VS McDonald's 5 Estrelas! 🍔⭐️\", 'comentarios': ['comi muito nesse mc às quartas feiras', 'Moito  BOM', 'Onde vocês vem as a avaliações?', 'Coragem ..tô fora', 'Eu acho que eu ia pular de felicidade', 'Todos é 5 estrela pq é de SJC 😂😂😂', 'é o neox que te copia, ou voce que copia o neox?', '@mcdonalds_br', '👏👏👏👏', 'quero um combro do big mc', '😋😋😋', 'prefiro o girafas, seu restaurante preferido!!', 'Nem sabia q existia essa diferença entre os MCs ..... Top o video !!👏👏', 'e cadê minha coquinha ein???', 'GARANTA AS SUAS BARRINHAS DA BOLD COM 10% OFF CLICANDO NO LINK DA MINHA BIO! 😍', 'avalia o bobs na proxima', 'slc esse segundo mc eu nunca fui', '🍔', 'Bk eh melhor', 'Mc Donald’s só é 5 estrelas, quando tem Pokemon no Mc Lanche Feliz. \\nBeijos.', 'slk mczinho deixou a desejar', 'Top 😂👏'], 'timestamp': '2024-07-26T15:00:00+0000'}, {'media_id': '18017206481183008', 'caption': 'Eu Me Tranquei Nesse Quarto! 😱', 'comentarios': ['kkkk eu já iria começar pela soneca 😂😂😂😂', 'Se nao dormisse nao perderia a hs 😂😂', 'só vc msm', '😂😂', 'só dormeeee', 'sem noção!!', 'A soneca te lascou kkkk', 'Ocio criativo!😂', '😮😮😮😮', 'Irmão até o fim do ano o milhão vem, seu conteúdo tá fod@@@ ❤️🔥', 'eu nao me trancaria no quarto do vasco', 'louco sempre foi né', '😂😂😂', 'Caramba, muito massa', 'A soneca te fudeu'], 'timestamp': '2024-07-24T15:00:00+0000'}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-34a78c349540>:11: UserWarning: Glyph 129401 (\\N{FACE HOLDING BACK TEARS}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(caminho)\n",
            "<ipython-input-8-34a78c349540>:11: UserWarning: Glyph 129322 (\\N{GRINNING FACE WITH ONE LARGE AND ONE SMALL EYE}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(caminho)\n",
            "<ipython-input-8-34a78c349540>:11: UserWarning: Glyph 129318 (\\N{FACE PALM}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(caminho)\n",
            "<ipython-input-8-34a78c349540>:11: UserWarning: Glyph 127995 (\\N{EMOJI MODIFIER FITZPATRICK TYPE-1-2}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(caminho)\n",
            "<ipython-input-8-34a78c349540>:11: UserWarning: Glyph 128587 (\\N{HAPPY PERSON RAISING ONE HAND}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(caminho)\n",
            "<ipython-input-8-34a78c349540>:11: UserWarning: Glyph 127828 (\\N{HAMBURGER}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(caminho)\n",
            "<ipython-input-8-34a78c349540>:11: UserWarning: Glyph 11088 (\\N{WHITE MEDIUM STAR}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(caminho)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}